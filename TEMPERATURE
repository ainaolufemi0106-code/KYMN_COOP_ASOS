#07182025 ALL CORRELATION OF TEMPERATURE BY DISTANCE
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker
import numpy as np

# Define all datasets
data1 = {
    'KYMN': ['SCTV', 'RSVL', 'BTCK', 'MRHD', 'MROK', 'GRHM', 'ELST', 'FCHV', 'FRNY', 'SCTV', 'BNVL', 'CRMT', 'BLRK'],
    'COOP': ['SCTK2', 'RUSK2', 'PNVK2', 'CRLK2', 'BRRK2', 'HNDK2', 'CSYK2', 'TVLK2', 'HNDK2', 'BRRK2', 'BCAK2', 'LMK', 'NOLK2'],
    'Distance': [1.23, 2.88, 8.48, 11.76, 12.83, 14.05, 16.22, 16.98, 18.88, 18.92, 20.40, 21.40, 21.59],
    'Correlation_Tmax': [0.997, 0.987, 0.995, 0.994, 0.987, 0.996, 0.996, 0.993, 0.995, 0.986, 0.988, 0.997, 0.982]
}

data2 = {
    'KYMN': ['FARM', 'LSML', 'HUEY', 'LXGN', 'HHTS', 'PVRT'],
    'COOP': ['BWG', 'FFT', 'CVG', 'LEX', 'CVG', 'OWB'],
    'Distance': [5.89, 7.86, 9.50, 9.68, 17.18, 21.61],
    'Correlation_Tmax': [0.999, 0.999, 0.997, 0.997, 0.997, 0.997]
}

data3 = {
    'KYMN': ['SCTV', 'RSVL', 'BTCK', 'MRHD', 'MROK', 'GRHM', 'ELST', 'FCHV', 'FRNY', 'SCTV', 'BNVL', 'CRMT', 'BLRK'],
    'COOP': ['SCTK2', 'RUSK2', 'PNVK2', 'CRLK2', 'BRRK2', 'HNDK2', 'CSYK2', 'TVLK2', 'HNDK2', 'BRRK2', 'BCAK2', 'LMK', 'NOLK2'],
    'Distance': [1.23, 2.88, 8.48, 11.76, 12.83, 14.05, 16.22, 16.98, 18.88, 18.92, 20.40, 21.40, 21.59],
    'Correlation_Tmin': [0.994, 0.987, 0.992, 0.987, 0.985, 0.989, 0.991, 0.988, 0.995, 0.983, 0.968, 0.991, 0.984]
}

data4 = {
    'KYMN': ['FARM', 'LSML', 'HUEY', 'LXGN', 'HHTS', 'PVRT'],
    'COOP': ['BWG', 'FFT', 'CVG', 'LEX', 'CVG', 'OWB'],
    'Distance': [5.89, 7.86, 9.50, 9.68, 17.18, 21.61],
    'Correlation_Tmin': [0.996, 0.997, 0.993, 0.993, 0.994, 0.988]
}

# Create DataFrames
df_tmax_coop = pd.DataFrame(data1)
df_tmax_asos = pd.DataFrame(data2)
df_tmin_coop = pd.DataFrame(data3)
df_tmin_asos = pd.DataFrame(data4)

# Initialize the plot
plt.figure(figsize=(8, 4))

# Plot Tmax datasets
plt.scatter(df_tmax_coop['Distance'], df_tmax_coop['Correlation_Tmax'],
            color='red', s=140, alpha=0.7, label='KYMN–COOP (Tmax)')
plt.scatter(df_tmax_asos['Distance'], df_tmax_asos['Correlation_Tmax'],
            color='red', s=140, alpha=0.7, marker='s', label='KYMN–ASOS (Tmax)')

# Plot Tmin datasets
plt.scatter(df_tmin_coop['Distance'], df_tmin_coop['Correlation_Tmin'],
            color='blue', s=80, alpha=0.7, label='KYMN–COOP (Tmin)')
plt.scatter(df_tmin_asos['Distance'], df_tmin_asos['Correlation_Tmin'],
            color='blue', s=80, alpha=0.7, marker='s', label='KYMN–ASOS (Tmin)')

# Annotate Tmax points
for i, row in df_tmax_coop.iterrows(): 
    plt.annotate(f"{row['KYMN']}-{row['COOP']}",
                 (row['Distance'], row['Correlation_Tmax']),
                 fontsize=8, ha='right', va='bottom')

for i, row in df_tmax_asos.iterrows():
    plt.annotate(f"{row['KYMN']}-{row['COOP']}",
                 (row['Distance'], row['Correlation_Tmax']),
                 fontsize=8, ha='left', va='top')

# Annotate Tmin points
for i, row in df_tmin_coop.iterrows(): 
    plt.annotate(f"{row['KYMN']}-{row['COOP']}",
                 (row['Distance'], row['Correlation_Tmin']),
                 fontsize=8, ha='right', va='bottom')

for i, row in df_tmin_asos.iterrows():
    plt.annotate(f"{row['KYMN']}-{row['COOP']}",
                 (row['Distance'], row['Correlation_Tmin']),
                 fontsize=8, ha='left', va='top')

# Axis labels and formatting
plt.xlabel('Distance (km)', fontsize=14)
plt.ylabel('Correlation coefficient', fontsize=14)
#plt.ylim(0.96, 1.001)
#plt.yticks(np.arange(0.97, 1.01, 0.01))
plt.yticks([0.97, 0.98, 0.99, 1.00])
plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%.2f'))

# Grid, legend, layout
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(fontsize=12)
plt.tight_layout()
plt.show()

# Optional: Save to file
# plt.savefig('Tmax_Tmin_correlation_vs_distance_labeled.png', dpi=300, bbox_inches='tight')
#=================================================================================================================================================================================
#06272025 MEAN SQUARED DIFF OF DAILY TMAX (SQUARED MEAN DAILY MAXIMUM TEMP OF PAIRED STATIONS PLOTTED AS A FUNCTION OF DISTANCE)
import pandas as pd
import matplotlib.pyplot as plt

# Define the first dataset (SCTV, RSVL, etc.)
data1 = {
    'KYMN': ['SCTV', 'RSVL', 'BTCK', 'MRHD', 'MROK', 'GRHM', 'ELST', 'FCHV', 'FRNY', 'SCTV', 'BNVL', 'CRMT', 'BLRK'],
    'COOP': ['SCTK2', 'RUSK2', 'PNVK2', 'CRLK2', 'BRRK2', 'HNDK2', 'CSYK2', 'TVLK2', 'HNDK2', 'BRRK2', 'BCAK2', 'LMK', 'NOLK2'],
    'Distance': [1.23, 2.88, 8.48, 11.76, 12.83, 14.05, 16.22, 16.98, 18.88, 18.92, 20.40, 21.4, 21.59],
    'Mean Squared Difference': [0.0289, 0.2401, 0.0144, 0.1521, 1.1881, 0.1024, 0.0576, 5.6169, 0, 0.5329, 1.4161, 0.0009, 4.41]
}

# Define the second dataset (FARM, QKSD, etc.)
data2 = {
    'KYMN': ['FARM', 'LSML', 'HUEY', 'LXGN', 'HHTS', 'PVRT'],
    'COOP': ['BWG', 'FFT', 'CVG', 'LEX', 'CVG', 'OWB'],
    'Distance': [5.89, 7.86, 9.50, 9.68, 17.18, 21.61],
    'Mean Squared Difference': [0.9604, 0.25, 0.5329, 1.0201, 0.3249, 0.1764]
}




# Create DataFrames
df1 = pd.DataFrame(data1)
df2 = pd.DataFrame(data2)

# Create the scatter plot
plt.figure(figsize=(10, 6))

# Plot the first dataset
plt.scatter(df1['Distance'], df1['Mean Squared Difference'], color='red', s=250, alpha=0.7, label='KYMN–COOP')

# Plot the second dataset
plt.scatter(df2['Distance'], df2['Mean Squared Difference'], color='#F08080', s=250, alpha=0.7, marker='s', label='KYMN–ASOS')

# Add annotations for the first dataset
for i, row in df1.iterrows():
    plt.annotate(f"{row['KYMN']}-{row['COOP']}", (row['Distance'], row['Mean Squared Difference']), fontsize=14, ha='right')

# Add annotations for the second dataset
for i, row in df2.iterrows():
    plt.annotate(f"{row['KYMN']}-{row['COOP']}", (row['Distance'], row['Mean Squared Difference']), fontsize=14, ha='right')

# Add labels and title
plt.xlabel('Distance (km)', fontsize=20)
plt.ylabel('Squared mean daily Tmax difference (°C²)', fontsize=17)
plt.ylim(0, 6) 
#plt.yticks(range(0, 3, 1))
plt.tick_params(axis='both', labelsize=14)
#plt.title('Scatter Plot of Distance vs Correlation')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(fontsize=16)

# Show the plot
plt.tight_layout()
plt.show()
#plt.savefig(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\corrplot.png', dpi=360, bbox_inches='tight')
#=================================================================================================================================================================================
#06272025 MEAN SQUARED DIFF OF DAILY TMIN (SQUARED MEAN DAILY MINIMUM TEMP OF PAIRED STATIONS PLOTTED AS A FUNCTION OF DISTANCE)
import pandas as pd
import matplotlib.pyplot as plt

# Define the first dataset (SCTV, RSVL, etc.)
data1 = {
    'KYMN': ['SCTV', 'RSVL', 'BTCK', 'MRHD', 'MROK', 'GRHM', 'ELST', 'FCHV', 'FRNY', 'SCTV', 'BNVL', 'CRMT', 'BLRK'],
    'COOP': ['SCTK2', 'RUSK2', 'PNVK2', 'CRLK2', 'BRRK2', 'HNDK2', 'CSYK2', 'TVLK2', 'HNDK2', 'BRRK2', 'BCAK2', 'LMK', 'NOLK2'],
    'Distance': [1.23, 2.88, 8.48, 11.76, 12.83, 14.05, 16.22, 16.98, 18.88, 18.92, 20.40, 21.4, 21.59],
    'Mean Squared Difference': [0.8649, 0.0169, 1, 0.2209, 0.36, 1.44, 0.04, 1.0404, 0.16, 1.0404, 0.81, 0.4761, 0.0324]
}

# Define the second dataset (FARM, QKSD, etc.)
data2 = {
    'KYMN': ['FARM', 'LSML', 'HUEY', 'LXGN', 'HHTS', 'PVRT'],
    'COOP': ['BWG', 'FFT', 'CVG', 'LEX', 'CVG', 'OWB'],
    'Distance': [5.89, 7.86, 9.50, 9.68, 17.18, 21.61],
    'Mean Squared Difference': [0.5625, 0.04, 0.0361, 0.0289, 0.0625, 1.2996]
}




# Create DataFrames
df1 = pd.DataFrame(data1)
df2 = pd.DataFrame(data2)

# Create the scatter plot
plt.figure(figsize=(10, 6))

# Plot the first dataset
plt.scatter(df1['Distance'], df1['Mean Squared Difference'], color='blue', s=250, alpha=0.7, label='KYMN–COOP')

# Plot the second dataset
plt.scatter(df2['Distance'], df2['Mean Squared Difference'], color='#87CEFA', s=250, alpha=0.7, marker='s', label='KYMN–ASOS')

# Add annotations for the first dataset
for i, row in df1.iterrows():
    plt.annotate(f"{row['KYMN']}-{row['COOP']}", (row['Distance'], row['Mean Squared Difference']), fontsize=14, ha='right')

# Add annotations for the second dataset
for i, row in df2.iterrows():
    plt.annotate(f"{row['KYMN']}-{row['COOP']}", (row['Distance'], row['Mean Squared Difference']), fontsize=14, ha='right')

# Add labels and title
plt.xlabel('Distance (km)', fontsize=20)
plt.ylabel('Squared mean daily Tmin difference (°C²)', fontsize=17)
plt.ylim(0, 6) 
#plt.yticks(range(0, 3, 1))
plt.tick_params(axis='both', labelsize=14)
#plt.title('Scatter Plot of Distance vs Correlation')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(fontsize=16)

# Show the plot
plt.tight_layout()
plt.show()
#plt.savefig(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\corrplot.png', dpi=360, bbox_inches='tight')
#=================================================================================================================================================================================
#06272025 MEAN SQUARED DIFF OF MONTHLY TMAX (SQUARED MEAN MONTHLY MAXIMUM TEMP OF PAIRED STATIONS PLOTTED AS A FUNCTION OF DISTANCE)
import pandas as pd
import matplotlib.pyplot as plt

# Define the first dataset (SCTV, RSVL, etc.)
data1 = {
    'KYMN': ['SCTV', 'RSVL', 'BTCK', 'MRHD', 'MROK', 'GRHM', 'ELST', 'FCHV', 'FRNY', 'SCTV', 'BNVL', 'CRMT', 'BLRK'],
    'COOP': ['SCTK2', 'RUSK2', 'PNVK2', 'CRLK2', 'BRRK2', 'HNDK2', 'CSYK2', 'TVLK2', 'HNDK2', 'BRRK2', 'BCAK2', 'LMK', 'NOLK2'],
    'Distance': [1.23, 2.88, 8.48, 11.76, 12.83, 14.05, 16.22, 16.98, 18.88, 18.92, 20.40, 21.4, 21.59],
    'Mean Squared Difference': [0.029241, 0.242064, 0.013689, 0.1521, 1.149184, 0.099225, 0.058564, 5.621641, 0.000001, 0.541696,
                                1.423249, 0.000841, 4.376464]
}


# Define the second dataset (FARM, QKSD, etc.)
data2 = {
    'KYMN': ['FARM', 'LSML', 'HUEY', 'LXGN', 'HHTS', 'PVRT'],
    'COOP': ['BWG', 'FFT', 'CVG', 'LEX', 'CVG', 'OWB'],
    'Distance': [5.89, 7.86, 9.50, 9.68, 17.18, 21.61],
    'Mean Squared Difference': [0.954529, 0.251001, 0.528529, 1.024144, 0.319225, 0.173056]
}




# Create DataFrames
df1 = pd.DataFrame(data1)
df2 = pd.DataFrame(data2)

# Create the scatter plot
plt.figure(figsize=(10, 6))

# Plot the first dataset
plt.scatter(df1['Distance'], df1['Mean Squared Difference'], color='red', s=250, alpha=0.7, label='KYMN–COOP')

# Plot the second dataset
plt.scatter(df2['Distance'], df2['Mean Squared Difference'], color='#F08080', s=250, alpha=0.7, marker='s', label='KYMN–ASOS')

# Add annotations for the first dataset
for i, row in df1.iterrows():
    plt.annotate(f"{row['KYMN']}-{row['COOP']}", (row['Distance'], row['Mean Squared Difference']), fontsize=14, ha='right')

# Add annotations for the second dataset
for i, row in df2.iterrows():
    plt.annotate(f"{row['KYMN']}-{row['COOP']}", (row['Distance'], row['Mean Squared Difference']), fontsize=14, ha='right')

# Add labels and title
plt.xlabel('Distance (km)', fontsize=20)
plt.ylabel('Squared mean monthly Tmax difference (°C²)', fontsize=17)
plt.ylim(0, 6) 
#plt.yticks(range(0, 3, 1))
plt.tick_params(axis='both', labelsize=14)
#plt.title('Scatter Plot of Distance vs Correlation')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(fontsize=16)

# Show the plot
plt.tight_layout()
plt.show()
#plt.savefig(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\corrplot.png', dpi=360, bbox_inches='tight')
#=================================================================================================================================================================================
06272025 MEAN SQUARED DIFF OF MONTHLY TMIN (SQUARED MEAN MONTHLY MINIMUM TEMP OF PAIRED STATIONS PLOTTED AS A FUNCTION OF DISTANCE)
import pandas as pd
import matplotlib.pyplot as plt

# Define the first dataset (SCTV, RSVL, etc.)
data1 = {
    'KYMN': ['SCTV', 'RSVL', 'BTCK', 'MRHD', 'MROK', 'GRHM', 'ELST', 'FCHV', 'FRNY', 'SCTV', 'BNVL', 'CRMT', 'BLRK'],
    'COOP': ['SCTK2', 'RUSK2', 'PNVK2', 'CRLK2', 'BRRK2', 'HNDK2', 'CSYK2', 'TVLK2', 'HNDK2', 'BRRK2', 'BCAK2', 'LMK', 'NOLK2'],
    'Distance': [1.23, 2.88, 8.48, 11.76, 12.83, 14.05, 16.22, 16.98, 18.88, 18.92, 20.40, 21.4, 21.59],
    'Mean Squared Difference': [0.8649, 0.016129, 1, 0.222784, 0.3721, 1.406596, 0.04, 1.0404, 0.155236, 1.028196, 0.802816,
                                0.478864, 0.031684]
}

# Define the second dataset (FARM, QKSD, etc.)
data2 = {
    'KYMN': ['FARM', 'LSML', 'HUEY', 'LXGN', 'HHTS', 'PVRT'],
    'COOP': ['BWG', 'FFT', 'CVG', 'LEX', 'CVG', 'OWB'],
    'Distance': [5.89, 7.86, 9.50, 9.68, 17.18, 21.61],
    'Mean Squared Difference': [0.564001, 0.039204, 0.036864, 0.030625, 0.0625, 1.308736]
}




# Create DataFrames
df1 = pd.DataFrame(data1)
df2 = pd.DataFrame(data2)

# Create the scatter plot
plt.figure(figsize=(10, 6))

# Plot the first dataset
plt.scatter(df1['Distance'], df1['Mean Squared Difference'], color='blue', s=250, alpha=0.7, label='KYMN–COOP')

# Plot the second dataset
plt.scatter(df2['Distance'], df2['Mean Squared Difference'], color='#87CEFA', s=250, alpha=0.7, marker='s', label='KYMN–ASOS')

# Add annotations for the first dataset
for i, row in df1.iterrows():
    plt.annotate(f"{row['KYMN']}-{row['COOP']}", (row['Distance'], row['Mean Squared Difference']), fontsize=14, ha='right')

# Add annotations for the second dataset
for i, row in df2.iterrows():
    plt.annotate(f"{row['KYMN']}-{row['COOP']}", (row['Distance'], row['Mean Squared Difference']), fontsize=14, ha='right')

# Add labels and title
plt.xlabel('Distance (km)', fontsize=20)
plt.ylabel('Squared mean monthly Tmin difference (°C²)', fontsize=17)
plt.ylim(0, 6) 
#plt.yticks(range(0, 3, 1))
plt.tick_params(axis='both', labelsize=14)
#plt.title('Scatter Plot of Distance vs Correlation')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(fontsize=16)

# Show the plot
plt.tight_layout()
plt.show()
#plt.savefig(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\corrplot.png', dpi=360, bbox_inches='tight')
#=================================================================================================================================================================================
#02252025 UPDATED CODE - AVERAGING WSPD AND SRAD @ 0600 TO 0600 SCTV COOP DATA  12 OBS 30 MIN B4 30 MIN AFTER
import pandas as pd

# Load the dataset
file_path = r"C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\ALL_2\AAA\Eastern\output_data_ELST.csv"
df = pd.read_csv(file_path)

# Ensure LocalTimestampCollected column exists
if 'LocalTimestampCollected' not in df.columns:
    raise KeyError("Column 'LocalTimestampCollected' is missing from the dataset.")

# Convert LocalTimestampCollected to datetime format
df['LocalTimestampCollected'] = pd.to_datetime(df['LocalTimestampCollected'], errors='coerce')

# Drop rows with NaT values in LocalTimestampCollected
df = df.dropna(subset=['LocalTimestampCollected'])

# Define the start and end times for filtering
start_time = pd.Timestamp("2010-12-31 06:00")
end_time = pd.Timestamp("2021-01-01 06:00")

# Filter data based on the time range
data = df[(df['LocalTimestampCollected'] >= start_time) & (df['LocalTimestampCollected'] <= end_time)].copy()

# Create a custom 'day' column that begins at 06:00 of each day
data['Day'] = data['LocalTimestampCollected'] - pd.to_timedelta(
    (data['LocalTimestampCollected'].dt.hour < 6).astype(int), unit='day'
)
data['Day'] = data['Day'].dt.date  # Extract only the date part

# Ensure sorting before rolling calculations
data = data.sort_values('LocalTimestampCollected')

# Compute rolling 1-hour averages for WSPD and SRAD (centered)
data = data.set_index('LocalTimestampCollected')
data['WSPD_1hr_avg'] = data['WSPD'].rolling('60min', center=True).mean()
data['SRAD_1hr_avg'] = data['SRAD'].rolling('60min', center=True).mean()
data = data.reset_index()

# Function to extract daily stats
def extract_daily_stats(group):
    if group['TAIR'].isna().all():  # Handle cases where all temperatures are NaN
        return pd.Series({'Tmax': None, 'Tmin': None, 'Tmax_time': None, 'Tmin_time': None,
                          'WSPD_avg_Tmax': None, 'SRAD_avg_Tmax': None,
                          'WSPD_avg_Tmin': None, 'SRAD_avg_Tmin': None})
    
    Tmax_idx = group['TAIR'].idxmax()
    Tmin_idx = group['TAIR'].idxmin()
    
    return pd.Series({
        'Tmax': group.loc[Tmax_idx, 'TAIR'],
        'Tmin': group.loc[Tmin_idx, 'TAIR'],
        'Tmax_time': group.loc[Tmax_idx, 'LocalTimestampCollected'],
        'Tmin_time': group.loc[Tmin_idx, 'LocalTimestampCollected'],
        'WSPD_avg_Tmax': group.loc[Tmax_idx, 'WSPD_1hr_avg'],
        'SRAD_avg_Tmax': group.loc[Tmax_idx, 'SRAD_1hr_avg'],
        'WSPD_avg_Tmin': group.loc[Tmin_idx, 'WSPD_1hr_avg'],
        'SRAD_avg_Tmin': group.loc[Tmin_idx, 'SRAD_1hr_avg']
    })

# Apply function to grouped data
results = data.groupby('Day').apply(extract_daily_stats).reset_index()

# Save the results to CSV
output_path = r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNCOOP\ELST.csv'
results.to_csv(output_path, index=False)

print(results.tail())
#=================================================================================================================================================================================
#02252025 UPDATED CODE - AVERAGING WSPD AND SRAD @ 0700 TO 0700 COOP DATA  12 OBS 30 MIN B4 30 MIN AFTER
import pandas as pd

# Load the dataset
file_path = r"C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\ALL_2\AAA\Central\output_data_BLRK.csv"
df = pd.read_csv(file_path)

# Ensure LocalTimestampCollected column exists
if 'LocalTimestampCollected' not in df.columns:
    raise KeyError("Column 'LocalTimestampCollected' is missing from the dataset.")

# Convert LocalTimestampCollected to datetime format
df['LocalTimestampCollected'] = pd.to_datetime(df['LocalTimestampCollected'], errors='coerce')

# Drop rows with NaT values in LocalTimestampCollected
df = df.dropna(subset=['LocalTimestampCollected'])

# Define the start and end times for filtering
start_time = pd.Timestamp("2010-12-31 07:00")
end_time = pd.Timestamp("2021-01-01 07:00")

# Filter data based on the time range
data = df[(df['LocalTimestampCollected'] >= start_time) & (df['LocalTimestampCollected'] <= end_time)].copy()

# Create a custom 'day' column that begins at 07:00 of each day
data['Day'] = data['LocalTimestampCollected'] - pd.to_timedelta(
    (data['LocalTimestampCollected'].dt.hour < 7).astype(int), unit='day'
)
data['Day'] = data['Day'].dt.date  # Extract only the date part

# Ensure sorting before rolling calculations
data = data.sort_values('LocalTimestampCollected')

# Compute rolling 1-hour averages for WSPD and SRAD (centered)
data = data.set_index('LocalTimestampCollected')
data['WSPD_1hr_avg'] = data['WSPD'].rolling('60min', center=True).mean()
data['SRAD_1hr_avg'] = data['SRAD'].rolling('60min', center=True).mean()
data = data.reset_index()

# Function to extract daily stats
def extract_daily_stats(group):
    if group['TAIR'].isna().all():  # Handle cases where all temperatures are NaN
        return pd.Series({'Tmax': None, 'Tmin': None, 'Tmax_time': None, 'Tmin_time': None,
                          'WSPD_avg_Tmax': None, 'SRAD_avg_Tmax': None,
                          'WSPD_avg_Tmin': None, 'SRAD_avg_Tmin': None})
    
    Tmax_idx = group['TAIR'].idxmax()
    Tmin_idx = group['TAIR'].idxmin()
    
    return pd.Series({
        'Tmax': group.loc[Tmax_idx, 'TAIR'],
        'Tmin': group.loc[Tmin_idx, 'TAIR'],
        'Tmax_time': group.loc[Tmax_idx, 'LocalTimestampCollected'],
        'Tmin_time': group.loc[Tmin_idx, 'LocalTimestampCollected'],
        'WSPD_avg_Tmax': group.loc[Tmax_idx, 'WSPD_1hr_avg'],
        'SRAD_avg_Tmax': group.loc[Tmax_idx, 'SRAD_1hr_avg'],
        'WSPD_avg_Tmin': group.loc[Tmin_idx, 'WSPD_1hr_avg'],
        'SRAD_avg_Tmin': group.loc[Tmin_idx, 'SRAD_1hr_avg']
    })

# Apply function to grouped data
results = data.groupby('Day').apply(extract_daily_stats).reset_index()

# Save the results to CSV
output_path = r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\Tmin\BLRK.csv'
results.to_csv(output_path, index=False)

print(results.head())
#=================================================================================================================================================================================
#02252025 UPDATED CODE - AVERAGING WSPD AND SRAD @ 0800 TO 0800 COOP DATA  12 OBS 30 MIN B4 30 MIN AFTER
import pandas as pd

# Load the dataset
file_path = r"C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\ALL_2\AAA\Eastern\output_data_ELST.csv"
df = pd.read_csv(file_path)

# Ensure LocalTimestampCollected column exists
if 'LocalTimestampCollected' not in df.columns:
    raise KeyError("Column 'LocalTimestampCollected' is missing from the dataset.")

# Convert LocalTimestampCollected to datetime format
df['LocalTimestampCollected'] = pd.to_datetime(df['LocalTimestampCollected'], errors='coerce')

# Drop rows with NaT values in LocalTimestampCollected
df = df.dropna(subset=['LocalTimestampCollected'])

# Define the start and end times for filtering
start_time = pd.Timestamp("2010-12-31 08:00")
end_time = pd.Timestamp("2021-01-01 08:00")

# Filter data based on the time range
data = df[(df['LocalTimestampCollected'] >= start_time) & (df['LocalTimestampCollected'] <= end_time)].copy()

# Create a custom 'day' column that begins at 07:00 of each day
data['Day'] = data['LocalTimestampCollected'] - pd.to_timedelta(
    (data['LocalTimestampCollected'].dt.hour < 8).astype(int), unit='day'
)
data['Day'] = data['Day'].dt.date  # Extract only the date part

# Ensure sorting before rolling calculations
data = data.sort_values('LocalTimestampCollected')

# Compute rolling 1-hour averages for WSPD and SRAD (centered)
data = data.set_index('LocalTimestampCollected')
data['WSPD_1hr_avg'] = data['WSPD'].rolling('60min', center=True).mean()
data['SRAD_1hr_avg'] = data['SRAD'].rolling('60min', center=True).mean()
data = data.reset_index()

# Function to extract daily stats
def extract_daily_stats(group):
    if group['TAIR'].isna().all():  # Handle cases where all temperatures are NaN
        return pd.Series({'Tmax': None, 'Tmin': None, 'Tmax_time': None, 'Tmin_time': None,
                          'WSPD_avg_Tmax': None, 'SRAD_avg_Tmax': None,
                          'WSPD_avg_Tmin': None, 'SRAD_avg_Tmin': None})
    
    Tmax_idx = group['TAIR'].idxmax()
    Tmin_idx = group['TAIR'].idxmin()
    
    return pd.Series({
        'Tmax': group.loc[Tmax_idx, 'TAIR'],
        'Tmin': group.loc[Tmin_idx, 'TAIR'],
        'Tmax_time': group.loc[Tmax_idx, 'LocalTimestampCollected'],
        'Tmin_time': group.loc[Tmin_idx, 'LocalTimestampCollected'],
        'WSPD_avg_Tmax': group.loc[Tmax_idx, 'WSPD_1hr_avg'],
        'SRAD_avg_Tmax': group.loc[Tmax_idx, 'SRAD_1hr_avg'],
        'WSPD_avg_Tmin': group.loc[Tmin_idx, 'WSPD_1hr_avg'],
        'SRAD_avg_Tmin': group.loc[Tmin_idx, 'SRAD_1hr_avg']
    })

# Apply function to grouped data
results = data.groupby('Day').apply(extract_daily_stats).reset_index()

# Save the results to CSV
output_path = r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\Tmin\ELST.csv'
results.to_csv(output_path, index=False)

print(results.head())
#=================================================================================================================================================================================
#02252025 UPDATED CODE AVERAGING WSPD AND SRAD @ 0000 TO 0000 CRMTLMK DATA  12 OBS 30 MIN B4 30 MIN AFTER
import pandas as pd

# Load the dataset
file_path = r"C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\ALL_2\AAA\Eastern\output_data_CRMT.csv"
df = pd.read_csv(file_path)

# Ensure LocalTimestampCollected column exists
if 'LocalTimestampCollected' not in df.columns:
    raise KeyError("Column 'LocalTimestampCollected' is missing from the dataset.")

# Convert LocalTimestampCollected to datetime format
df['LocalTimestampCollected'] = pd.to_datetime(df['LocalTimestampCollected'], errors='coerce')

# Drop rows with NaT values in LocalTimestampCollected
df = df.dropna(subset=['LocalTimestampCollected'])

# Define the start and end times for filtering
start_time = pd.Timestamp("2010-12-31 00:00")
end_time = pd.Timestamp("2021-01-01 00:00")

# Filter data based on the time range
data = df[
    (df['LocalTimestampCollected'] >= start_time) &
    (df['LocalTimestampCollected'] <= end_time)
].copy()

# Create a custom 'Day' column that begins at 00:00 of each day
data['Day'] = (data['LocalTimestampCollected'].dt.floor('D') + pd.Timedelta(hours=1))

# Extract only the date part for clarity
data['Day'] = data['Day'].dt.date

# Ensure sorting before rolling calculations
data = data.sort_values('LocalTimestampCollected')

# Compute rolling 1-hour averages for WSPD and SRAD (centered)
data = data.set_index('LocalTimestampCollected')
data['WSPD_1hr_avg'] = data['WSPD'].rolling('60min', center=True).mean()
data['SRAD_1hr_avg'] = data['SRAD'].rolling('60min', center=True).mean()
data = data.reset_index()

# Function to extract daily stats
def extract_daily_stats(group):
    if group['TAIR'].isna().all():  # Handle cases where all temperatures are NaN
        return pd.Series({'Tmax': None, 'Tmin': None, 'Tmax_time': None, 'Tmin_time': None,
                          'WSPD_avg_Tmax': None, 'SRAD_avg_Tmax': None,
                          'WSPD_avg_Tmin': None, 'SRAD_avg_Tmin': None})
    
    Tmax_idx = group['TAIR'].idxmax()
    Tmin_idx = group['TAIR'].idxmin()
    
    return pd.Series({
        'Tmax': group.loc[Tmax_idx, 'TAIR'],
        'Tmin': group.loc[Tmin_idx, 'TAIR'],
        'Tmax_time': group.loc[Tmax_idx, 'LocalTimestampCollected'],
        'Tmin_time': group.loc[Tmin_idx, 'LocalTimestampCollected'],
        'WSPD_avg_Tmax': group.loc[Tmax_idx, 'WSPD_1hr_avg'],
        'SRAD_avg_Tmax': group.loc[Tmax_idx, 'SRAD_1hr_avg'],
        'WSPD_avg_Tmin': group.loc[Tmin_idx, 'WSPD_1hr_avg'],
        'SRAD_avg_Tmin': group.loc[Tmin_idx, 'SRAD_1hr_avg']
    })

# Apply function to grouped data
results = data.groupby('Day').apply(extract_daily_stats).reset_index()

# Save the results to CSV
output_path = r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\Tmin\CRMT.csv'
results.to_csv(output_path, index=False)

print(results.head())
#=================================================================================================================================================================================
#02252025 UPDATED CODE AVERAGING WSPD AND SRAD FOR PRNC @ 1700 TO 1700 COOP DATA  12 OBS 30 MIN B4 30 MIN AFTER
import pandas as pd

# Load the dataset
file_path = r"C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\AAA\Central\output_data_PRNC.csv"
df = pd.read_csv(file_path)

# Ensure LocalTimestampCollected column exists
if 'LocalTimestampCollected' not in df.columns:
    raise KeyError("Column 'LocalTimestampCollected' is missing from the dataset.")

# Convert LocalTimestampCollected to datetime format
df['LocalTimestampCollected'] = pd.to_datetime(df['LocalTimestampCollected'], errors='coerce')

# Drop rows with NaT values in LocalTimestampCollected
df = df.dropna(subset=['LocalTimestampCollected'])

# Define the start and end times for filtering
start_time = pd.Timestamp("2010-12-31 17:00")
end_time = pd.Timestamp("2021-01-01 17:00")

# Filter data based on the time range
data = df[(df['LocalTimestampCollected'] >= start_time) & (df['LocalTimestampCollected'] <= end_time)].copy()

# Create a custom 'day' column that begins at 17:00 of each day
data['Day'] = data['LocalTimestampCollected'] - pd.to_timedelta(
    (data['LocalTimestampCollected'].dt.hour < 17).astype(int), unit='day'
)
data['Day'] = data['Day'].dt.date  # Extract only the date part

# Ensure sorting before rolling calculations
data = data.sort_values('LocalTimestampCollected')

# Compute rolling 1-hour averages for WSPD and SRAD (centered)
data = data.set_index('LocalTimestampCollected')
data['WSPD_1hr_avg'] = data['WSPD'].rolling('60min', center=True).mean()
data['SRAD_1hr_avg'] = data['SRAD'].rolling('60min', center=True).mean()
data = data.reset_index()

# Function to extract daily stats
def extract_daily_stats(group):
    if group['TAIR'].isna().all():  # Handle cases where all temperatures are NaN
        return pd.Series({'Tmax': None, 'Tmin': None, 'Tmax_time': None, 'Tmin_time': None,
                          'WSPD_avg_Tmax': None, 'SRAD_avg_Tmax': None,
                          'WSPD_avg_Tmin': None, 'SRAD_avg_Tmin': None})
    
    Tmax_idx = group['TAIR'].idxmax()
    Tmin_idx = group['TAIR'].idxmin()
    
    return pd.Series({
        'Tmax': group.loc[Tmax_idx, 'TAIR'],
        'Tmin': group.loc[Tmin_idx, 'TAIR'],
        'Tmax_time': group.loc[Tmax_idx, 'LocalTimestampCollected'],
        'Tmin_time': group.loc[Tmin_idx, 'LocalTimestampCollected'],
        'WSPD_avg_Tmax': group.loc[Tmax_idx, 'WSPD_1hr_avg'],
        'SRAD_avg_Tmax': group.loc[Tmax_idx, 'SRAD_1hr_avg'],
        'WSPD_avg_Tmin': group.loc[Tmin_idx, 'WSPD_1hr_avg'],
        'SRAD_avg_Tmin': group.loc[Tmin_idx, 'SRAD_1hr_avg']
    })

# Apply function to grouped data
results = data.groupby('Day').apply(extract_daily_stats).reset_index()

# Save the results to CSV
output_path = r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNCOOP\PRNC.csv'
results.to_csv(output_path, index=False)

print(results.head())
#=================================================================================================================================================================================
#02252025 UPDATED PROCESS KYMN TO MATCH ASOS 1 AM-1AM AND 1 HR AVERAGE WSPD N SRAD 
import pandas as pd

# Load the dataset
file_path = r"C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\ALL_2\AAA\Central\output_data_FARM.csv"
df = pd.read_csv(file_path)

# Convert LocalTimestampCollected to datetime format
df['LocalTimestampCollected'] = pd.to_datetime(df['LocalTimestampCollected'])

# Define the start and end times for filtering
start_time = pd.Timestamp("2011-01-01 01:00")
end_time = pd.Timestamp("2021-01-01 01:00")

# Filter data based on the time range
data = df[
    (df['LocalTimestampCollected'] >= start_time) & 
    (df['LocalTimestampCollected'] <= end_time)
].copy()

# Create a custom 'Day' column that begins at 01:00 of each day
data = data.assign(Day=(data['LocalTimestampCollected'] - pd.Timedelta(hours=1)).dt.floor('D') + pd.Timedelta(hours=1))

# Extract only the date part for clarity
data['Day'] = data['Day'].dt.date

# Compute Tmax and Tmin FIRST
tmax_tmin = data.groupby('Day')['TAIR'].agg(Tmax='max', Tmin='min').reset_index()

# Find timestamps when Tmax and Tmin occur
tmax_timestamps = data.loc[data.groupby('Day')['TAIR'].idxmax(), ['Day', 'LocalTimestampCollected']].rename(columns={'LocalTimestampCollected': 'Tmax_time'})
tmin_timestamps = data.loc[data.groupby('Day')['TAIR'].idxmin(), ['Day', 'LocalTimestampCollected']].rename(columns={'LocalTimestampCollected': 'Tmin_time'})

# Merge Tmax/Tmin timestamps into the main results
results = tmax_tmin.merge(tmax_timestamps, on='Day').merge(tmin_timestamps, on='Day')

# Ensure sorting before rolling calculations
data = data.sort_values('LocalTimestampCollected').set_index('LocalTimestampCollected')

# Compute rolling 1-hour averages for WSPD and SRAD (centered)
data['WSPD_1hr_avg'] = data['WSPD'].rolling('60min', center=True).mean()
data['SRAD_1hr_avg'] = data['SRAD'].rolling('60min', center=True).mean()
data = data.reset_index()

# Merge WSPD and SRAD 1-hour averages at Tmax and Tmin times
results = results.merge(data[['LocalTimestampCollected', 'WSPD_1hr_avg', 'SRAD_1hr_avg']], 
                        left_on='Tmax_time', right_on='LocalTimestampCollected', how='left') \
                 .rename(columns={'WSPD_1hr_avg': 'WSPD_avg_Tmax', 'SRAD_1hr_avg': 'SRAD_avg_Tmax'}) \
                 .drop(columns=['LocalTimestampCollected'])

results = results.merge(data[['LocalTimestampCollected', 'WSPD_1hr_avg', 'SRAD_1hr_avg']], 
                        left_on='Tmin_time', right_on='LocalTimestampCollected', how='left') \
                 .rename(columns={'WSPD_1hr_avg': 'WSPD_avg_Tmin', 'SRAD_1hr_avg': 'SRAD_avg_Tmin'}) \
                 .drop(columns=['LocalTimestampCollected'])


# Display the final results
print(results.tail())

# Save the final results to a CSV file
output_path = r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\Tmin\FARM.csv'
results.to_csv(output_path, index=False)
#=================================================================================================================================================================================
#02262025 PERCENTAGE OF MISSING DATA
import matplotlib.pyplot as plt

# Data: COOP stations and their respective missing data percentages
stations = ["SCTK2", "RUSK2", "MRNK2", "PNVK2", "DIXK2", "CRLK2", "HNDK2", 
            "CSYK2", "TVLK2", "PRSK2", "BRRK2", "CRFK2", "BCAK2", "LMK", "NOLK2"]

missing_data_percentages = [0, 0, 100, 0.6, 100, 0.2, 1.4, 0.1, 0.2, 
                            100, 1.0, 100.0, 3.1, 0, 0]

# Sort data by missing data percentage for better readability
sorted_data = sorted(zip(missing_data_percentages, stations), reverse=True)
sorted_percentages, sorted_stations = zip(*sorted_data)

# Define colors based on percentage threshold
colors = ['red' if p >= 50 else 'orange' if p >= 10 else 'green' for p in sorted_percentages]

# Plotting the horizontal bar chart
plt.figure(figsize=(10, 6))
plt.barh(sorted_stations, sorted_percentages, color=colors)
plt.xlabel('Percentage of missing data', fontsize=24)
#plt.title('COOP Stations - Percentage of Missing Data', fontsize=18)
plt.ylabel("Stations", fontsize=24)
plt.tick_params(axis='both', labelsize=16)
plt.gca().invert_yaxis()  # Invert y-axis to have the highest percentages at the top

# Add percentage labels on the bars
for i, (percent, station) in enumerate(zip(sorted_percentages, sorted_stations)):
    plt.text(percent + 0.5, i, f"{percent:.1f}%", va='center', fontsize= 16, color='black')

plt.show()
#=================================================================================================================================================================================
#03032025 PROCESSING KYMN OR ASOS DAILY DATA INTO MONTHLY AVERAGES
import pandas as pd

# Load the CSV file
df = pd.read_csv(r"C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNCOOP\BLRKNOLK2.csv")

# Convert 'Day' column to datetime format
df['Day'] = pd.to_datetime(df['Day'], errors='coerce')

# Set 'Day' as the index for resampling
df.set_index('Day', inplace=True)

# Compute monthly averages using resampling
monthly_averages = df[['Tmax', 'Tmin', 'Tmax1', 'Tmin1', 
                       'WSPD_avg_Tmax', 'SRAD_avg_Tmax', 'WSPD_avg_Tmin']].resample('M').mean()

# Reset index to save the result properly
monthly_averages.reset_index(inplace=True)

# Save the resampled data
monthly_averages.to_csv(r"C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNCOOP\KYMNCOOP_M\BLRKNOLK2_M.csv", index=False)

# Display the first few rows
print(monthly_averages.head())
#=================================================================================================================================================================================
#03052025 BOXPLOTS FOR MONTHLY KYMNASOS
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNASOS\ALL\ALLSTN_KYMNASOS2.csv', parse_dates=["Date"])

# Extract the month from the Date column
df["Month"] = df["Date"].dt.month

# Define the month order (ensuring December is not plotted first)
month_order = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]  

# Create the box plot without outliers
plt.figure(figsize=(8, 4))
sns.boxplot(x="Month", y="Tmin-Tmin1", data=df, palette="coolwarm", showfliers=False, order=month_order)

# Customize the plot
plt.xlabel("Months")
plt.ylabel("KYMN - ASOS (◦C)")
plt.ylim(-5, 5)
#plt.title("Monthly Box Plots for KYMN - ASOS Differences (Outliers Removed)")
plt.xticks(ticks=range(12), labels=["J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N", "D"])

# Show the plot
plt.show()
#=================================================================================================================================================================================
#03052025 BOXPLOTS FOR MONTHLY KYMNCOOP
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNCOOP\ALL\ALLSTN_KYMNCOOP2.csv', parse_dates=["Date"])
# Extract the month from the Date column
df["Month"] = df["Date"].dt.month

# Define the month order (ensuring December is not plotted first)
month_order = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]  

# Create the box plot without outliers
plt.figure(figsize=(8, 4))
sns.boxplot(x="Month", y="Tmin-Tmin1", data=df, palette="coolwarm", showfliers=False, order=month_order)

# Customize the plot
plt.xlabel("Months")
plt.ylabel("KYMN - COOP (◦C)")
plt.ylim(-5, 5)
#plt.title("Monthly Box Plots for KYMN - ASOS Differences (Outliers Removed)")
plt.xticks(ticks=range(12), labels=["J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N", "D"])

# Show the plot
plt.show()
#=================================================================================================================================================================================
#03112025 WELCH's t-STATISTICS
import pandas as pd
from scipy.stats import ttest_ind

# Load the dataset
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNASOS\ALL\ALLSTN_KYMNASOS.csv')

# Convert KYMN and COOP to numeric, coercing errors to NaN
df['Tmax'] = pd.to_numeric(df['Tmax'], errors='coerce')
df['Tmax1'] = pd.to_numeric(df['Tmax1'], errors='coerce')

# Drop rows with NaN values in KYMN or COOP
df_clean = df.dropna(subset=['Tmax', 'Tmax1'])

# Extract cleaned KYMN and COOP values
tmax_values = df_clean['Tmax']
tmax1_values = df_clean['Tmax1']

# Perform an independent t-test
t_stat, p_value = ttest_ind(tmax_values, tmax1_values, equal_var=False)

# Print the results
print(f"t-statistic: {t_stat}, p-value: {p_value}")
#=================================================================================================================================================================================
#03152025 OVERALL KYMN Tmax BY ASOS Tmax by KYMN Tmax OR KYMN Tmax by COOP Tmax
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNCOOP\ALL\ALLSTN_KYMNCOOP.csv')

# Define the bin assignment function
def assign_bin(TAIR):
    if TAIR <= -10:
        return "<-10"
    elif -10 < TAIR <= -7.5:
        return "-10 to -7.5"
    elif -7.5 < TAIR <= -5:
        return "-7.5 to -5"
    elif -5 < TAIR <= -2.5:
        return "-5 to -2.5"
    elif -2.5 < TAIR <= 0:
        return "-2.5 to 0"
    elif 0 < TAIR <= 2.5:
        return "0 to 2.5"  
    elif 2.5 < TAIR <= 5:
        return "2.5 to 5"
    elif 5 < TAIR <= 7.5:
        return "5 to 7.5"
    elif 7.5 < TAIR <= 10:
        return "7.5 to 10"
    elif 10 < TAIR <= 12.5:
        return "10 to 12.5"
    elif 12.5 < TAIR <= 15:
        return "12.5 to 15"
    elif 15 < TAIR <= 17.5:
        return "15 to 17.5"
    elif 17.5 < TAIR <= 20:
        return "17.5 to 20"
    elif 20 < TAIR <= 22.5:
        return "20 to 22.5"
    elif 22.5 < TAIR <= 25:
        return "22.5 to 25"
    elif 25 < TAIR <= 27.5:
        return "25 to 27.5"
    elif 27.5 < TAIR <= 30:
        return "27.5 to 30"
    elif 30 < TAIR <= 32.5:
        return "30 to 32.5"
    elif 32.5 < TAIR <= 35:
        return "32.5 to 35"
    elif 35 < TAIR <= 37.5:
        return "35 to 37.5"
    elif 37.5 < TAIR <= 40:
        return "37.5 to 40"
    elif TAIR > 40:  
        return ">40"
    
# Calculate the difference and create a new column 'KYMN_minus_COOP'
df['Tmin_minus_Tmin1'] = df['Tmin'] - df['Tmin1']

# Apply the binning function to 'KYMN' and set it as an ordered categorical type
df['Tmin_Bin'] = df['Tmin'].apply(assign_bin)

# Define the order of the bins
bin_order = ["<-10", "-10 to -7.5", "-7.5 to -5",  "-5 to -2.5", "-2.5 to 0", "0 to 2.5", "2.5 to 5",
                          "5 to 7.5", "7.5 to 10", "10 to 12.5", "12.5 to 15", "15 to 17.5", "17.5 to 20", 
                          "20 to 22.5", "22.5 to 25", "25 to 27.5", "27.5 to 30", "30 to 32.5", "32.5 to 35", 
                          "35 to 37.5", "37.5 to 40", ">40"]

# Convert 'KYMN_Bin' to an ordered categorical type
df['Tmin_Bin'] = pd.Categorical(df['Tmin_Bin'], categories=bin_order, ordered=True)

# Calculate the average of KYMN_minus_COOP for each bin
average_diff_per_bin = df.groupby('Tmin_Bin', observed=True)['Tmin_minus_Tmin1'].mean()

# Calculate the count of data points in each bin
bin_counts = df.groupby('Tmin_Bin', observed=True)['Tmin_minus_Tmin1'].count()

# Plotting the bar chart
plt.figure(figsize=(10, 6))
ax = average_diff_per_bin.plot(kind='bar', color='blue', edgecolor='black')

# Add only the sample sizes (without 'n=') on top or below each bar
for i, count in enumerate(bin_counts):
    if i in [0, 1, 2, 3, 4, 5, 16, 17, 18, 20, 19, 21]:  # Specify indices where the sample size should go below
        ax.text(i, average_diff_per_bin[i] - 0.2, f'{count}', ha='center', va='top', fontsize=12)
    elif i in [5, 7, 22, 23, 24, 25, 26, 27, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]:  # Specify indices where the sample size should go above
        ax.text(i, average_diff_per_bin[i] + 0.2, f'{count}', ha='center', va='bottom', fontsize=12)
    else:  # Default for remaining indices (if any)
        ax.text(i, average_diff_per_bin[i] + 0.5, f'{count}', ha='center', va='bottom', fontsize=12)


# Customize the plot
plt.xlabel('KYMN (Tmin °C)', fontsize=18)
plt.ylabel('Average KYMN - COOP (Tmin °C)', fontsize=18)
plt.tick_params(axis='both', labelsize=24)
plt.grid(True, axis='y')
plt.xticks(rotation=90, fontsize=16)
plt.ylim(-2, 2)  # Adjust based on your data range
plt.yticks(rotation=0, fontsize=16)
plt.tight_layout()

# Show the plot
plt.show()
#=================================================================================================================================================================================
#03152025 OVERALL KYMN Tmin BY ASOS Tmin by KYMN Tmin OR KYMN Tmin by COOP Tmin
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNASOS\ALL\ALLSTN_KYMNASOS.csv')

# Define the bin assignment function
def assign_bin(TAIR):
    if TAIR <= -10:
        return "<-10"
    elif -10 < TAIR <= -7.5:
        return "-10 to -7.5"
    elif -7.5 < TAIR <= -5:
        return "-7.5 to -5"
    elif -5 < TAIR <= -2.5:
        return "-5 to -2.5"
    elif -2.5 < TAIR <= 0:
        return "-2.5 to 0"
    elif 0 < TAIR <= 2.5:
        return "0 to 2.5"  
    elif 2.5 < TAIR <= 5:
        return "2.5 to 5"
    elif 5 < TAIR <= 7.5:
        return "5 to 7.5"
    elif 7.5 < TAIR <= 10:
        return "7.5 to 10"
    elif 10 < TAIR <= 12.5:
        return "10 to 12.5"
    elif 12.5 < TAIR <= 15:
        return "12.5 to 15"
    elif 15 < TAIR <= 17.5:
        return "15 to 17.5"
    elif 17.5 < TAIR <= 20:
        return "17.5 to 20"
    elif 20 < TAIR <= 22.5:
        return "20 to 22.5"
    elif 22.5 < TAIR <= 25:
        return "22.5 to 25"
    elif 25 < TAIR <= 27.5:
        return "25 to 27.5"
    elif 27.5 < TAIR <= 30:
        return "27.5 to 30"
    elif 30 < TAIR <= 32.5:
        return "30 to 32.5"
    elif 32.5 < TAIR <= 35:
        return "32.5 to 35"
    elif 35 < TAIR <= 37.5:
        return "35 to 37.5"
    elif 37.5 < TAIR <= 40:
        return "37.5 to 40"
    elif TAIR > 40:  
        return ">40"
    
# Calculate the difference and create a new column 'KYMN_minus_COOP'
df['Tmax_minus_Tmax1'] = df['Tmax'] - df['Tmax1']

# Apply the binning function to 'KYMN' and set it as an ordered categorical type
df['Tmax_Bin'] = df['Tmax'].apply(assign_bin)

# Define the order of the bins
bin_order = ["<-10", "-10 to -7.5", "-7.5 to -5",  "-5 to -2.5", "-2.5 to 0", "0 to 2.5", "2.5 to 5",
                          "5 to 7.5", "7.5 to 10", "10 to 12.5", "12.5 to 15", "15 to 17.5", "17.5 to 20", 
                          "20 to 22.5", "22.5 to 25", "25 to 27.5", "27.5 to 30", "30 to 32.5", "32.5 to 35", 
                          "35 to 37.5", "37.5 to 40", ">40"]


#bin_order = ["<-4", "-4 to -3", "-3 to -2", "-2 to -1", "-1 to 0", "0 to 1", "1 to 2", "2 to 3", "3 to 4", ">4"]


# Convert 'KYMN_Bin' to an ordered categorical type
df['Tmax_Bin'] = pd.Categorical(df['Tmax_Bin'], categories=bin_order, ordered=True)

# Calculate the average of KYMN_minus_COOP for each bin
average_diff_per_bin = df.groupby('Tmax_Bin', observed=True)['Tmax_minus_Tmax1'].mean()

# Calculate the count of data points in each bin
bin_counts = df.groupby('Tmax_Bin', observed=True)['Tmax_minus_Tmax1'].count()

# Plotting the bar chart
plt.figure(figsize=(10, 6))
ax = average_diff_per_bin.plot(kind='bar', color='red', edgecolor='black')

# Add only the sample sizes (without 'n=') on top or below each bar
for i, count in enumerate(bin_counts):
    if i in [0, 1, 3, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 21, 15, 16, 17, 18, 20]:  # Specify indices where the sample size should go below
        ax.text(i, average_diff_per_bin[i] - 0.2, f'{count}', ha='center', va='top', fontsize=12)
    elif i in [22, 23, 24, 25, 26, 27]:  # Specify indices where the sample size should go above
        ax.text(i, average_diff_per_bin[i] + 0.2, f'{count}', ha='center', va='bottom', fontsize=12)
    else:  # Default for remaining indices (if any)
        ax.text(i, average_diff_per_bin[i] + 0.5, f'{count}', ha='center', va='bottom', fontsize=12)


# Customize the plot
plt.xlabel('KYMN (Tmax°C)', fontsize=18)
plt.ylabel('Average KYMN - ASOS (Tmax °C)', fontsize=18)
plt.tick_params(axis='both', labelsize=24)
plt.grid(True, axis='y')
plt.xticks(rotation=90, fontsize=16)
plt.ylim(-2, 2)  # Adjust based on your data range
plt.yticks(rotation=0, fontsize=16)
plt.tight_layout()

# Show the plot
plt.show()
#=================================================================================================================================================================================
#03312025 UPDATED OVERALL KYMNASOS TMAX DIFF BY WSPD AROUND TMAX (MEAN DAILY TEMP DIFF PLOTTED AS A FUNCTION OF WINDSPEED)
#KYMN-ASOS
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\ALLKYMNASOSUPDATED.csv')

# Ensure the columns 'Tmin', 'Tmin1', and 'WSPD' are numeric
df['Tmax'] = pd.to_numeric(df['Tmax'], errors='coerce')
df['Tmax1'] = pd.to_numeric(df['Tmax1'], errors='coerce')
df['WSPD'] = pd.to_numeric(df['WSPD'], errors='coerce')

# Convert the 'Date' column to datetime format
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
elif 'LocalTimestampCollected' in df.columns:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected'])

# Remove rows with missing values in key columns
df.dropna(subset=['Tmax', 'Tmax1', 'WSPD'], inplace=True)

# Define the bin assignment function for wind speed
def assign_bin(WSPD):
    if WSPD == 0:
        return "0"
    elif 0 < WSPD <= 2.5:    
        return ">0 to 2.5"
    elif 2.5 < WSPD <= 5:      
        return ">2.5 to 5"
    elif 5 < WSPD <= 7.5:     
        return ">5 to 7.5"
    elif 7.5 < WSPD <= 10:    
        return ">7.5 to 10"
    elif WSPD > 10:      
        return ">10"

# Compute the difference between Tmin and Tmin1
df['Tmax_minus_Tmax1'] = df['Tmax'] - df['Tmax1']

# Apply the binning function to 'WSPD' and set it as an ordered categorical type
df['WSPD_Bin'] = df['WSPD'].apply(assign_bin)

# Define the order of the bins
bin_order = ["0", ">0 to 2.5", ">2.5 to 5", ">5 to 7.5", ">7.5 to 10", ">10"]

# Convert 'WSPD_Bin' to an ordered categorical type
df['WSPD_Bin'] = pd.Categorical(df['WSPD_Bin'], categories=bin_order, ordered=True)

# Calculate the average of Tmin_minus_Tmin1 for each bin
average_diff_per_bin = df.groupby('WSPD_Bin', observed=True)['Tmax_minus_Tmax1'].mean()

# Calculate the count of data points in each bin
bin_counts = df.groupby('WSPD_Bin', observed=True)['Tmax_minus_Tmax1'].count()

# Plotting the bar chart
plt.figure(figsize=(8, 4))
ax = average_diff_per_bin.plot(kind='bar', color='grey', edgecolor='red')

# Add only the sample sizes (without 'n=') on top or below each bar
for i, count in enumerate(bin_counts):
    if i in [0, 1, 2, 3, 4, 5, 8, 19, 21]:  # Specify indices where the sample size should go below
        ax.text(i, average_diff_per_bin[i] - 0.5, f'{count}', ha='center', va='top', fontsize=12)
    elif i in [5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27]:  # Specify indices where the sample size should go above
        ax.text(i, average_diff_per_bin[i] + 0.2, f'{count}', ha='center', va='bottom', fontsize=13)
    else:  # Default for remaining indices (if any)
        ax.text(i, average_diff_per_bin[i] + 0.5, f'{count}', ha='center', va='bottom', fontsize=13)

# Customize the plot
plt.xlabel('WSPD (m/s)', fontsize=14)
plt.ylabel('Average KYMN - ASOS (Tmax °C)', fontsize=14)
plt.grid(True, axis='y')
plt.xticks(rotation=0, fontsize=14)
plt.ylim(-2, 2) 
plt.yticks(range(-2, 3, 1))
plt.yticks(fontsize=16)

# Show the plot
plt.show()
#=================================================================================================================================================================================
#03312025 UPDATED OVERALL KYMNCOOP TMAX DIFF BY WSPD AROUND TMAX(MEAN DAILY TEMP DIFF PLOTTED AS A FUNCTION OF WINDSPEED)
#KYMN-COOP
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\ALLKYMNCOOPUPDATED.csv')

# Ensure the columns 'Tmin', 'Tmin1', and 'WSPD' are numeric
df['Tmax'] = pd.to_numeric(df['Tmax'], errors='coerce')
df['Tmax1'] = pd.to_numeric(df['Tmax1'], errors='coerce')
df['WSPD'] = pd.to_numeric(df['WSPD'], errors='coerce')

# Convert the 'Date' column to datetime format
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
elif 'LocalTimestampCollected' in df.columns:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected'])

# Remove rows with missing values in key columns
df.dropna(subset=['Tmax', 'Tmax1', 'WSPD'], inplace=True)

# Define the bin assignment function for wind speed
def assign_bin(WSPD):
    if WSPD == 0:
        return "0"
    elif 0 < WSPD <= 2.5:    
        return ">0 to 2.5"
    elif 2.5 < WSPD <= 5:      
        return ">2.5 to 5"
    elif 5 < WSPD <= 7.5:     
        return ">5 to 7.5"
    elif 7.5 < WSPD <= 10:    
        return ">7.5 to 10"
    elif WSPD > 10:      
        return ">10"

# Compute the difference between Tmin and Tmin1
df['Tmax_minus_Tmax1'] = df['Tmax'] - df['Tmax1']

# Apply the binning function to 'WSPD' and set it as an ordered categorical type
df['WSPD_Bin'] = df['WSPD'].apply(assign_bin)

# Define the order of the bins
bin_order = ["0", ">0 to 2.5", ">2.5 to 5", ">5 to 7.5", ">7.5 to 10", ">10"]

# Convert 'WSPD_Bin' to an ordered categorical type
df['WSPD_Bin'] = pd.Categorical(df['WSPD_Bin'], categories=bin_order, ordered=True)

# Calculate the average of Tmin_minus_Tmin1 for each bin
average_diff_per_bin = df.groupby('WSPD_Bin', observed=True)['Tmax_minus_Tmax1'].mean()

# Calculate the count of data points in each bin
bin_counts = df.groupby('WSPD_Bin', observed=True)['Tmax_minus_Tmax1'].count()

# Plotting the bar chart
plt.figure(figsize=(8, 4))
ax = average_diff_per_bin.plot(kind='bar', color='grey', edgecolor='red')

# Add only the sample sizes (without 'n=') on top or below each bar
for i, count in enumerate(bin_counts):
    if i in [0, 1, 2, 3, 4, 5, 8, 19, 21]:  # Specify indices where the sample size should go below
        ax.text(i, average_diff_per_bin[i] - 0.5, f'{count}', ha='center', va='top', fontsize=12)
    elif i in [5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27]:  # Specify indices where the sample size should go above
        ax.text(i, average_diff_per_bin[i] + 0.2, f'{count}', ha='center', va='bottom', fontsize=13)
    else:  # Default for remaining indices (if any)
        ax.text(i, average_diff_per_bin[i] + 0.5, f'{count}', ha='center', va='bottom', fontsize=13)

# Customize the plot
plt.xlabel('WSPD (m/s)', fontsize=14)
plt.ylabel('Average KYMN - COOP (Tmax °C)', fontsize=14)
plt.grid(True, axis='y')
plt.xticks(rotation=0, fontsize=14)
plt.ylim(-2, 2) 
plt.yticks(range(-2, 3, 1))
plt.yticks(fontsize=16)

# Show the plot
plt.show()
#=================================================================================================================================================================================
#03312025 UPDATED OVERALL KYMNASOS TMIN DIFF BY WSPD AROUND TMIN (MEAN DAILY TEMP DIFF PLOTTED AS A FUNCTION OF WINDSPEED)
#KYMN-ASOS
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\Tmin\KYMNASOS_Tmin_SRAD_WSPD.csv')

# Ensure the columns 'Tmin', 'Tmin1', and 'WSPD' are numeric
df['Tmin'] = pd.to_numeric(df['Tmin'], errors='coerce')
df['WSPD'] = pd.to_numeric(df['WSPD'], errors='coerce')

# Convert the 'Date' column to datetime format
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
elif 'LocalTimestampCollected' in df.columns:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected'])

# Remove rows with missing values in key columns
df.dropna(subset=['Tmin', 'WSPD'], inplace=True)

# Define the bin assignment function for wind speed
def assign_bin(WSPD):
    if WSPD == 0:
        return "0"
    elif 0 < WSPD <= 2.5:    
        return ">0 to 2.5"
    elif 2.5 < WSPD <= 5:      
        return ">2.5 to 5"
    elif 5 < WSPD <= 7.5:     
        return ">5 to 7.5"
    elif 7.5 < WSPD <= 10:    
        return ">7.5 to 10"
    elif WSPD > 10:      
        return ">10"


# Apply the binning function to 'WSPD' and set it as an ordered categorical type
df['WSPD_Bin'] = df['WSPD'].apply(assign_bin)

# Define the order of the bins
bin_order = ["0", ">0 to 2.5", ">2.5 to 5", ">5 to 7.5", ">7.5 to 10", ">10"]

# Convert 'WSPD_Bin' to an ordered categorical type
df['WSPD_Bin'] = pd.Categorical(df['WSPD_Bin'], categories=bin_order, ordered=True)

# Calculate the average of Tmin_minus_Tmin1 for each bin
average_diff_per_bin = df.groupby('WSPD_Bin', observed=True)['Tmin'].mean()

# Calculate the count of data points in each bin
bin_counts = df.groupby('WSPD_Bin', observed=True)['Tmin'].count()

# Plotting the bar chart
plt.figure(figsize=(8, 4))
ax = average_diff_per_bin.plot(kind='bar', color='grey', edgecolor='blue')

# Add only the sample sizes (without 'n=') on top or below each bar
for i, count in enumerate(bin_counts):
    if i in [0, 1, 2, 3, 4, 8, 19, 21]:  # Specify indices where the sample size should go below
        ax.text(i, average_diff_per_bin[i] - 0.5, f'{count}', ha='center', va='top', fontsize=12)
    elif i in [ 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27]:  # Specify indices where the sample size should go above
        ax.text(i, average_diff_per_bin[i] + 0.2, f'{count}', ha='center', va='bottom', fontsize=13)
    else:  # Default for remaining indices (if any)
        ax.text(i, average_diff_per_bin[i] + 0.5, f'{count}', ha='center', va='bottom', fontsize=13)


# Customize the plot
plt.xlabel('WSPD (m/s)', fontsize=14)
plt.ylabel('Average KYMN - ASOS (Tmin °C)', fontsize=14)
plt.grid(True, axis='y')
plt.xticks(rotation=0, fontsize=14)
plt.ylim(-2, 2) 
plt.yticks(range(-2, 3, 1))
plt.yticks(fontsize=16)

# Show the plot
plt.show()
#=================================================================================================================================================================================
#03312025 UPDATED OVERALL KYMNCOOP TMIN DIFF BY WSPD AROUND TMIN (MEAN DAILY TEMP DIFF PLOTTED AS A FUNCTION OF WINDSPEED)
#KYMN-COOP
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\Tmin\KYMNCOOP_Tmin_SRAD_WSPD.csv')

# Ensure the columns 'Tmin', 'Tmin1', and 'WSPD' are numeric
df['Tmin'] = pd.to_numeric(df['Tmin'], errors='coerce')
df['WSPD'] = pd.to_numeric(df['WSPD'], errors='coerce')

# Convert the 'Date' column to datetime format
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
elif 'LocalTimestampCollected' in df.columns:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected'])

# Remove rows with missing values in key columns
df.dropna(subset=['Tmin', 'WSPD'], inplace=True)

# Define the bin assignment function for wind speed
def assign_bin(WSPD):
    if WSPD == 0:
        return "0"
    elif 0 < WSPD <= 2.5:    
        return ">0 to 2.5"
    elif 2.5 < WSPD <= 5:      
        return ">2.5 to 5"
    elif 5 < WSPD <= 7.5:     
        return ">5 to 7.5"
    elif 7.5 < WSPD <= 10:    
        return ">7.5 to 10"
    elif WSPD > 10:      
        return ">10"


# Apply the binning function to 'WSPD' and set it as an ordered categorical type
df['WSPD_Bin'] = df['WSPD'].apply(assign_bin)

# Define the order of the bins
bin_order = ["0", ">0 to 2.5", ">2.5 to 5", ">5 to 7.5", ">7.5 to 10", ">10"]

# Convert 'WSPD_Bin' to an ordered categorical type
df['WSPD_Bin'] = pd.Categorical(df['WSPD_Bin'], categories=bin_order, ordered=True)

# Calculate the average of Tmin_minus_Tmin1 for each bin
average_diff_per_bin = df.groupby('WSPD_Bin', observed=True)['Tmin'].mean()

# Calculate the count of data points in each bin
bin_counts = df.groupby('WSPD_Bin', observed=True)['Tmin'].count()

# Plotting the bar chart
plt.figure(figsize=(8, 4))
ax = average_diff_per_bin.plot(kind='bar', color='grey', edgecolor='blue')

# Add only the sample sizes (without 'n=') on top or below each bar
for i, count in enumerate(bin_counts):
    if i in [0, 1]:  # Specify indices where the sample size should go below
        ax.text(i, average_diff_per_bin[i] - 0.5, f'{count}', ha='center', va='top', fontsize=12)
    elif i in [ 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27]:  # Specify indices where the sample size should go above
        ax.text(i, average_diff_per_bin[i] + 0.2, f'{count}', ha='center', va='bottom', fontsize=13)
    else:  # Default for remaining indices (if any)
        ax.text(i, average_diff_per_bin[i] + 0.5, f'{count}', ha='center', va='bottom', fontsize=13)


# Customize the plot
plt.xlabel('WSPD (m/s)', fontsize=14)
plt.ylabel('Average KYMN - COOP (Tmin °C)', fontsize=14)
plt.grid(True, axis='y')
plt.xticks(rotation=0, fontsize=14)
plt.ylim(-2, 2) 
plt.yticks(range(-2, 3, 1))
plt.yticks(fontsize=16)

# Show the plot
plt.show()
#=================================================================================================================================================================================
#03262025 BY NETWORK KYMNCOOP TMAX BY SRAD (MEAN DAILY TMAX DIFF PLOTTED AS A FUNCTION OF SOLAR RADIATION)
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNCOOP\ALL\ALLSTN_KYMNCOOP.csv')

# Ensure the columns 'Tmax', 'Tmax1', and 'WSPD' are numeric
df['Tmax'] = pd.to_numeric(df['Tmax'], errors='coerce')
df['Tmax1'] = pd.to_numeric(df['Tmax1'], errors='coerce')
df['SRAD'] = pd.to_numeric(df['SRAD'], errors='coerce')

# Convert the 'Date' column to datetime if it exists
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
else:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected']).dt.date

# Define the bin assignment function for wind speed
def assign_bin(SRAD):
    if SRAD == 0:
        return "0" 
    elif 0 < SRAD <= 100:    
        return ">0 to 100"
    elif 100 < SRAD <= 200:      
        return ">100 to 200"
    elif 200 < SRAD <= 300:     
        return ">200 to 300"
    elif 300 < SRAD <= 400:    
        return ">300 to 400"
    elif 400 < SRAD <= 500:    
        return ">400 to 500"
    elif 500 < SRAD <= 600:    
        return ">500 to 600"
    elif 600 < SRAD <= 700:    
        return ">600 to 700"
    elif 700 < SRAD <= 800:    
        return ">700 to 800"
    elif 800 < SRAD <= 900:    
        return ">800 to 900"
    elif 900 < SRAD <= 1000:    
        return ">900 to 1000"
    elif SRAD > 1000:      
        return ">1000"
 
    
# Calculate the difference and create a new column 'Tmax_minus_Tmax1'
df['Tmax_minus_Tmax1'] = df['Tmax'] - df['Tmax1']


# Apply the binning function to 'WSPD' and set it as an ordered categorical type
df['SRAD_Bin'] = df['SRAD'].apply(assign_bin)

# Define the order of the bins
bin_order = ["0", ">0 to 100", ">100 to 200", ">200 to 300", ">300 to 400", ">400 to 500", ">500 to 600", ">600 to 700",
            ">700 to 800", ">800 to 900", ">900 to 1000",  ">1000"]


# Convert 'WSPD_Bin' to an ordered categorical type
df['SRAD_Bin'] = pd.Categorical(df['SRAD_Bin'], categories=bin_order, ordered=True)

# Calculate the average of Tmax_minus_Tmax1 for each bin
average_diff_per_bin = df.groupby('SRAD_Bin', observed=True)['Tmax_minus_Tmax1'].mean()

# Calculate the count of data points in each bin
bin_counts = df.groupby('SRAD_Bin', observed=True)['Tmax_minus_Tmax1'].count()

# Plotting the bar chart
plt.figure(figsize=(10, 6))
ax = average_diff_per_bin.plot(kind='bar', color='#FF6666', edgecolor='black')

# Add only the sample sizes (without 'n=') on top or below each bar
for i, count in enumerate(bin_counts):
    if i in [1, 2, 5, 6, 7, 9, 10, 11, 3, 4, 8, 19, 21]:  # Specify indices where the sample size should go below
        ax.text(i, average_diff_per_bin[i] - 0.2, f'{count}', ha='center', va='top', fontsize=14)
    elif i in [0, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27]:  # Specify indices where the sample size should go above
        ax.text(i, average_diff_per_bin[i] + 0.2, f'{count}', ha='center', va='bottom', fontsize=14)
    else:  # Default for remaining indices (if any)
        ax.text(i, average_diff_per_bin[i] + 0.5, f'{count}', ha='center', va='bottom', fontsize=14)


# Customize the plot
plt.xlabel('SRAD (W/m²)', fontsize=20)
plt.ylabel('Average KYMN - COOP (Tmax °C)', fontsize=20)
plt.tick_params(axis='both', labelsize=24)
#plt.title('Average Tmax - Tmax1 vs WSPD Binned Values')  # Optional title
plt.grid(True, axis='y')
plt.xticks(rotation=90, fontsize=16)
plt.ylim(-2, 2) 
plt.yticks(fontsize=16)

# Show the plot
plt.show()
#=================================================================================================================================================================================
#03262025 BY NETWORK KYMNASOS TMAX BY SRAD (MEAN DAILY TMAX DIFF PLOTTED AS A FUNCTION OF SOLAR RADIATION)
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNASOS\ALL\ALLSTN_KYMNASOS.csv')

# Ensure the columns 'Tmax', 'Tmax1', and 'WSPD' are numeric
df['Tmax'] = pd.to_numeric(df['Tmax'], errors='coerce')
df['Tmax1'] = pd.to_numeric(df['Tmax1'], errors='coerce')
df['SRAD'] = pd.to_numeric(df['SRAD'], errors='coerce')

# Convert the 'Date' column to datetime if it exists
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
else:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected']).dt.date

# Define the bin assignment function for wind speed
def assign_bin(SRAD):
    if SRAD == 0:
        return "0" 
    elif 0 < SRAD <= 100:    
        return ">0 to 100"
    elif 100 < SRAD <= 200:      
        return ">100 to 200"
    elif 200 < SRAD <= 300:     
        return ">200 to 300"
    elif 300 < SRAD <= 400:    
        return ">300 to 400"
    elif 400 < SRAD <= 500:    
        return ">400 to 500"
    elif 500 < SRAD <= 600:    
        return ">500 to 600"
    elif 600 < SRAD <= 700:    
        return ">600 to 700"
    elif 700 < SRAD <= 800:    
        return ">700 to 800"
    elif 800 < SRAD <= 900:    
        return ">800 to 900"
    elif 900 < SRAD <= 1000:    
        return ">900 to 1000"
    elif SRAD > 1000:      
        return ">1000"
 
    
# Calculate the difference and create a new column 'Tmax_minus_Tmax1'
df['Tmax_minus_Tmax1'] = df['Tmax'] - df['Tmax1']


# Apply the binning function to 'WSPD' and set it as an ordered categorical type
df['SRAD_Bin'] = df['SRAD'].apply(assign_bin)

# Define the order of the bins
bin_order = ["0", ">0 to 100", ">100 to 200", ">200 to 300", ">300 to 400", ">400 to 500", ">500 to 600", ">600 to 700",
            ">700 to 800", ">800 to 900", ">900 to 1000",  ">1000"]


# Convert 'WSPD_Bin' to an ordered categorical type
df['SRAD_Bin'] = pd.Categorical(df['SRAD_Bin'], categories=bin_order, ordered=True)

# Calculate the average of Tmax_minus_Tmax1 for each bin
average_diff_per_bin = df.groupby('SRAD_Bin', observed=True)['Tmax_minus_Tmax1'].mean()

# Calculate the count of data points in each bin
bin_counts = df.groupby('SRAD_Bin', observed=True)['Tmax_minus_Tmax1'].count()

# Plotting the bar chart
plt.figure(figsize=(10, 6))
ax = average_diff_per_bin.plot(kind='bar', color='#FF6666', edgecolor='black')

# Add only the sample sizes (without 'n=') on top or below each bar
for i, count in enumerate(bin_counts):
    if i in [0, 1, 2, 5, 6, 7, 9, 10, 11, 3, 4, 8, 19, 21]:  # Specify indices where the sample size should go below
        ax.text(i, average_diff_per_bin[i] - 0.2, f'{count}', ha='center', va='top', fontsize=14)
    elif i in [11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27]:  # Specify indices where the sample size should go above
        ax.text(i, average_diff_per_bin[i] + 0.2, f'{count}', ha='center', va='bottom', fontsize=14)
    else:  # Default for remaining indices (if any)
        ax.text(i, average_diff_per_bin[i] + 0.5, f'{count}', ha='center', va='bottom', fontsize=14)


# Customize the plot
plt.xlabel('SRAD (W/m²)', fontsize=20)
plt.ylabel('Average KYMN - ASOS (Tmax °C)', fontsize=20)
plt.tick_params(axis='both', labelsize=24)
#plt.title('Average Tmax - Tmax1 vs WSPD Binned Values')  # Optional title
plt.grid(True, axis='y')
plt.xticks(rotation=90, fontsize=16)
plt.ylim(-2, 2) 
plt.yticks(fontsize=16)

# Show the plot
plt.show()
#=================================================================================================================================================================================
#04132025 ANOMALY KYMNASOS TMAX DIFF BY SRAD (MEAN DAILY TMAX DIFF PLOTTED AS A FUNCTION OF SOLAR RADIATION)
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\ANOMA.csv')

# Ensure the columns 'Tmax', 'Tmax1', and 'WSPD' are numeric
df['Tmax_Anom'] = pd.to_numeric(df['Tmax_Anom'], errors='coerce')
#df['Tmax1'] = pd.to_numeric(df['Tmax1'], errors='coerce')
df['SRAD'] = pd.to_numeric(df['SRAD'], errors='coerce')

# Convert the 'Date' column to datetime if it exists
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
else:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected']).dt.date

# Define the bin assignment function for wind speed
def assign_bin(SRAD):
    if SRAD == 0:
        return "0" 
    elif 0 < SRAD <= 100:    
        return ">0 to 100"
    elif 100 < SRAD <= 200:      
        return ">100 to 200"
    elif 200 < SRAD <= 300:     
        return ">200 to 300"
    elif 300 < SRAD <= 400:    
        return ">300 to 400"
    elif 400 < SRAD <= 500:    
        return ">400 to 500"
    elif 500 < SRAD <= 600:    
        return ">500 to 600"
    elif 600 < SRAD <= 700:    
        return ">600 to 700"
    elif 700 < SRAD <= 800:    
        return ">700 to 800"
    elif 800 < SRAD <= 900:    
        return ">800 to 900"
    elif 900 < SRAD <= 1000:    
        return ">900 to 1000"
    elif SRAD > 1000:      
        return ">1000"
 
    
# Calculate the difference and create a new column 'Tmax_minus_Tmax1'

#df['Tmax_Anom'] = df['Tmax_Anom']


# Apply the binning function to 'WSPD' and set it as an ordered categorical type
df['SRAD_Bin'] = df['SRAD'].apply(assign_bin)

# Define the order of the bins
bin_order = ["0", ">0 to 100", ">100 to 200", ">200 to 300", ">300 to 400", ">400 to 500", ">500 to 600", ">600 to 700",
            ">700 to 800", ">800 to 900", ">900 to 1000",  ">1000"]


# Convert 'WSPD_Bin' to an ordered categorical type
df['SRAD_Bin'] = pd.Categorical(df['SRAD_Bin'], categories=bin_order, ordered=True)

# Calculate the average of Tmax_minus_Tmax1 for each bin
average_diff_per_bin = df.groupby('SRAD_Bin', observed=True)['Tmax_Anom'].mean()

# Calculate the count of data points in each bin
bin_counts = df.groupby('SRAD_Bin', observed=True)['Tmax_Anom'].count()

# Plotting the bar chart
plt.figure(figsize=(10, 6))
ax = average_diff_per_bin.plot(kind='bar', color='#FF6666', edgecolor='black')

# Add only the sample sizes (without 'n=') on top or below each bar
for i, count in enumerate(bin_counts):
    if i in [5, 6, 7, 8, 9, 10, 11, 19, 21]:  # Specify indices where the sample size should go below
        ax.text(i, average_diff_per_bin[i] - 0.2, f'{count}', ha='center', va='top', fontsize=14)
    elif i in [0, 1, 2, 3, 4, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27]:  # Specify indices where the sample size should go above
        ax.text(i, average_diff_per_bin[i] + 0.2, f'{count}', ha='center', va='bottom', fontsize=14)
    else:  # Default for remaining indices (if any)
        ax.text(i, average_diff_per_bin[i] + 0.5, f'{count}', ha='center', va='bottom', fontsize=14)


# Customize the plot

plt.xlabel('SRAD (W/m²)', fontsize=18)
plt.ylabel('Average KYMN - ASOS Anomaly (Tmax °C)', fontsize=16)
plt.tick_params(axis='both', labelsize=24)
#plt.title('Average Tmax Difference Anomaly vs SRAD Binned Values')  # Optional title
plt.grid(True, axis='y')
plt.xticks(rotation=90, fontsize=16)
plt.ylim(-2, 2) 
plt.yticks(fontsize=16)

# Show the plot
plt.show()
#=================================================================================================================================================================================
#04132025 ANOMALY KYMNASOS TMAX DIFF BY SRAD (MEAN DAILY TMAX DIFF PLOTTED AS A FUNCTION OF SOLAR RADIATION)
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\ANOM.csv')

# Ensure the columns 'Tmax', 'Tmax1', and 'WSPD' are numeric
df['Tmax_Anom'] = pd.to_numeric(df['Tmax_Anom'], errors='coerce')
#df['Tmax1'] = pd.to_numeric(df['Tmax1'], errors='coerce')
df['SRAD'] = pd.to_numeric(df['SRAD'], errors='coerce')

# Convert the 'Date' column to datetime if it exists
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
else:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected']).dt.date

# Define the bin assignment function for wind speed
def assign_bin(SRAD):
    if SRAD == 0:
        return "0" 
    elif 0 < SRAD <= 100:    
        return ">0 to 100"
    elif 100 < SRAD <= 200:      
        return ">100 to 200"
    elif 200 < SRAD <= 300:     
        return ">200 to 300"
    elif 300 < SRAD <= 400:    
        return ">300 to 400"
    elif 400 < SRAD <= 500:    
        return ">400 to 500"
    elif 500 < SRAD <= 600:    
        return ">500 to 600"
    elif 600 < SRAD <= 700:    
        return ">600 to 700"
    elif 700 < SRAD <= 800:    
        return ">700 to 800"
    elif 800 < SRAD <= 900:    
        return ">800 to 900"
    elif 900 < SRAD <= 1000:    
        return ">900 to 1000"
    elif SRAD > 1000:      
        return ">1000"
 
    
# Calculate the difference and create a new column 'Tmax_minus_Tmax1'

#df['Tmax_Anom'] = df['Tmax_Anom']


# Apply the binning function to 'WSPD' and set it as an ordered categorical type
df['SRAD_Bin'] = df['SRAD'].apply(assign_bin)

# Define the order of the bins
bin_order = ["0", ">0 to 100", ">100 to 200", ">200 to 300", ">300 to 400", ">400 to 500", ">500 to 600", ">600 to 700",
            ">700 to 800", ">800 to 900", ">900 to 1000",  ">1000"]


# Convert 'WSPD_Bin' to an ordered categorical type
df['SRAD_Bin'] = pd.Categorical(df['SRAD_Bin'], categories=bin_order, ordered=True)

# Calculate the average of Tmax_minus_Tmax1 for each bin
average_diff_per_bin = df.groupby('SRAD_Bin', observed=True)['Tmax_Anom'].mean()

# Calculate the count of data points in each bin
bin_counts = df.groupby('SRAD_Bin', observed=True)['Tmax_Anom'].count()

# Plotting the bar chart
plt.figure(figsize=(10, 6))
ax = average_diff_per_bin.plot(kind='bar', color='#FF6666', edgecolor='black')

# Add only the sample sizes (without 'n=') on top or below each bar
for i, count in enumerate(bin_counts):
    if i in [ 3, 4, 5, 6, 7, 8, 9, 10, 11, 19, 21]:  # Specify indices where the sample size should go below
        ax.text(i, average_diff_per_bin[i] - 0.2, f'{count}', ha='center', va='top', fontsize=14)
    elif i in [0, 1, 2, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27]:  # Specify indices where the sample size should go above
        ax.text(i, average_diff_per_bin[i] + 0.2, f'{count}', ha='center', va='bottom', fontsize=14)
    else:  # Default for remaining indices (if any)
        ax.text(i, average_diff_per_bin[i] + 0.5, f'{count}', ha='center', va='bottom', fontsize=14)


# Customize the plot

plt.xlabel('SRAD (W/m²)', fontsize=18)
plt.ylabel('Average KYMN - COOP Anomaly (Tmax °C)', fontsize=16)
plt.tick_params(axis='both', labelsize=24)
#plt.title('Average Tmax Difference Anomaly vs SRAD Binned Values')  # Optional title
plt.grid(True, axis='y')
plt.xticks(rotation=90, fontsize=16)
plt.ylim(-2, 2) 
plt.yticks(fontsize=16)

# Show the plot
plt.show()
#=================================================================================================================================================================================
#05192025 OVERALL MEAN MONTHLY TMAX AND MEAN MONTHLY DIFF KYMNASOS
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def plot_dual_axis_chart(months, kymn, asos, diff):
    x = np.arange(len(months))  # Label locations
    width = 0.3  # Width of bars

    fig, ax1 = plt.subplots(figsize=(8, 5))

    # Primary axis (KYMN and COOP)
    ax1.bar(x - width/2, kymn, width, label="KYMN", color='#F08080')
    ax1.bar(x + width/2, asos, width, label="ASOS", color='red')
    #plt.xlabel('Months)', fontsize=14)
    ax1.set_ylabel("Mean monthly Tmax (°C)", fontsize=14)
    ax1.set_xticks(x)
    ax1.set_xticklabels(months)
    ax1.legend(loc='upper left')
    
    # Secondary axis (DIFF)
    ax2 = ax1.twinx()
    #ax2.bar(x + width*1.5, diff, width, label="DIFF", color='black')
    ax2.bar(x + width*1.5, diff, width, label="DIFF", hatch='///', color = 'gray')
    ax2.set_ylabel("Mean monthly difference  (°C)", color='black', fontsize=14)
    ax2.set_ylim(-2, 2)  # Set scale from -1.0 to 1.0

    # Title and final formatting
    #plt.title("KYMN vs ASOS with DIFF on Secondary Axis")
    ax2.legend(loc='upper right')
    plt.show()
    

days = ["JAN", "FEB", "MAR", "APR", "MAY", "JUN", "JUL", "AUG", "SEP", "OCT", "NOV", "DEC"]
kymn_values = [5.21250451, 7.972251829, 13.06010955, 19.37894851, 24.30139318, 28.31251333, 29.9128693, 28.93264505, 
               26.32302321, 19.97166628, 12.65049585, 8.35566508]
asos_values = [5.603578256, 8.403358648, 13.59763441, 19.98471926, 25.10394264, 29.33943209, 31.03476105, 29.95332139, 
               27.2401509, 20.5760806, 13.15493827, 8.794940263]
diff_values = [-0.391073745, -0.431106819, -0.537524859, -0.605770746, -0.802549466, -1.026918753, -1.12189175, -1.020676332,
               -0.917127692, -0.604414317, -0.504442417, -0.439275183]

# Run function
plot_dual_axis_chart(days, kymn_values, asos_values, diff_values)
#=================================================================================================================================================================================
#05192025 OVERALL MEAN MONTHLY TMAX AND MEAN MONTHLY DIFF KYMNCOOP
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def plot_dual_axis_chart(months, kymn, coop, diff):
    x = np.arange(len(months))  # Label locations
    width = 0.3  # Width of bars

    fig, ax1 = plt.subplots(figsize=(8, 5))

    # Primary axis (KYMN and COOP)
    ax1.bar(x - width/2, kymn, width, label="KYMN", color='#F08080')
    ax1.bar(x + width/2, coop, width, label="COOP", color='red')
    #plt.xlabel('Months)', fontsize=14)
    ax1.set_ylabel("Mean monthly Tmax (°C)", fontsize=14)
    ax1.set_xticks(x)
    ax1.set_xticklabels(months)
    ax1.legend(loc='upper left')
    
    # Secondary axis (DIFF)
    ax2 = ax1.twinx()
    #ax2.bar(x + width*1.5, diff, width, label="DIFF", color='black')
    ax2.bar(x + width*1.5, diff, width, label="DIFF", hatch='///', color = 'gray')
    ax2.set_ylabel("Mean monthly difference  (°C)", color='black', fontsize=14)
    ax2.set_ylim(-2, 2)  # Set scale from -1.0 to 1.0

    # Title and final formatting
    #plt.title("KYMN vs ASOS with DIFF on Secondary Axis")
    ax2.legend(loc='upper right')
    plt.show()
    

days = ["JAN", "FEB", "MAR", "APR", "MAY", "JUN", "JUL", "AUG", "SEP", "OCT", "NOV", "DEC"]
kymn_values = [5.862836955, 8.775020564, 13.81917998, 20.01136113, 24.66591328, 28.69882604, 30.28055791, 29.30670463,
               27.08891109, 20.79769709, 13.38476071, 9.243647339]
coop_values = [6.2704517, 9.242066262, 14.30539587, 20.64836209, 25.26657224, 29.32920304, 31.01280716, 29.9886333,
               27.54736756, 21.24141843, 13.81536535, 9.501696626]
diff_values = [-0.407614745, -0.467045699, -0.486215894, -0.63700096, -0.600658957, -0.630377006, -0.73224925,-0.681928678,
               -0.45845647, -0.443721335, -0.43060464,-0.258049287]

# Run function
plot_dual_axis_chart(days, kymn_values, coop_values, diff_values)
#=================================================================================================================================================================================
#05192025 OVERALL MEAN MONTHLY TMIN AND MEAN MONTHLY DIFF KYMNASOS
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def plot_dual_axis_chart(months, kymn, asos, diff):
    x = np.arange(len(months))  # Label locations
    width = 0.3  # Width of bars

    fig, ax1 = plt.subplots(figsize=(8, 5))

    # Primary axis (KYMN and COOP)
    ax1.bar(x - width/2, kymn, width, label="KYMN", color='#87CEFA')
    ax1.bar(x + width/2, asos, width, label="ASOS", color='blue')
    #plt.xlabel('Months)', fontsize=14)
    ax1.set_ylabel("Mean monthly Tmin (°C)", fontsize=14)
    ax1.set_xticks(x)
    ax1.set_xticklabels(months)
    ax1.legend(loc='upper left')

    # Secondary axis (DIFF)
    ax2 = ax1.twinx()
    #ax2.bar(x + width*1.5, diff, width, label="DIFF", color='black')
    ax2.bar(x + width*1.5, diff, width, label="DIFF", hatch='///', color = 'gray')
    ax2.set_ylabel("Mean monthly difference  (°C)", color='black', fontsize=14)
    ax2.set_ylim(-2, 2)  # Set scale from -1.0 to 1.0

    # Title and final formatting
    #plt.title("KYMN vs ASOS with DIFF on Secondary Axis")
    ax2.legend(loc='upper right')
    plt.show()
    

days = ["JAN", "FEB", "MAR", "APR", "MAY", "JUN", "JUL", "AUG", "SEP", "OCT", "NOV", "DEC"]
kymn_values = [-4.071270914, -2.072284011, 2.455143077, 7.505170157, 13.56942219, 17.47490676, 19.6195219, 18.28582684, 
               14.88996645, 8.406691697, 1.692983491, -0.366205541]
asos_values = [-3.917013142, -1.971090586, 2.447933094, 7.564418673, 13.74976702, 17.85429629, 20.09890084, 18.78221027,
               15.3501747, 8.692964739, 1.886117284, -0.208410992]
diff_values = [-0.154257772, -0.101193426, 0.007209983, -0.059248516, -0.18034483, -0.379389527, -0.479378939, -0.496383431,
               -0.460208247, -0.286273043, -0.193133793, -0.15779455]

# Run function
plot_dual_axis_chart(days, kymn_values, asos_values, diff_values)
#=================================================================================================================================================================================
#05192025 OVERALL MEAN MONTHLY TMIN AND MEAN MONTHLY DIFF KYMNCOOP
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def plot_dual_axis_chart(months, kymn, coop, diff):
    x = np.arange(len(months))  # Label locations
    width = 0.3  # Width of bars

    fig, ax1 = plt.subplots(figsize=(8, 5))

    # Primary axis (KYMN and COOP)
    ax1.bar(x - width/2, kymn, width, label="KYMN", color='#87CEFA')
    ax1.bar(x + width/2, coop, width, label="COOP", color='blue')
    #plt.xlabel('Months)', fontsize=14)
    ax1.set_ylabel("Mean monthly Tmin (°C)", fontsize=14)
    ax1.set_xticks(x)
    ax1.set_xticklabels(months)
    ax1.legend(loc='upper left')

    # Secondary axis (DIFF)
    ax2 = ax1.twinx()
    #ax2.bar(x + width*1.5, diff, width, label="DIFF", color='black')
    ax2.bar(x + width*1.5, diff, width, label="DIFF", hatch='///', color = 'gray')
    ax2.set_ylabel("Mean monthly difference  (°C)", color='black', fontsize=14)
    ax2.set_ylim(-2, 2)  # Set scale from -1.0 to 1.0

    # Title and final formatting
    #plt.title("KYMN vs ASOS with DIFF on Secondary Axis")
    ax2.legend(loc='upper right')
    plt.show()
    

days = ["JAN", "FEB", "MAR", "APR", "MAY", "JUN", "JUL", "AUG", "SEP", "OCT", "NOV", "DEC"]
kymn_values = [-4.567449774, -2.621297964, 1.57934256, 6.374526755, 12.85017903, 16.91935006, 19.14022941, 17.59416792,
               14.2697885, 7.471939001, 0.761890892, -0.896506969]
coop_values = [-4.390767069, -2.447659408, 1.680589931, 6.579912744, 12.94107698, 17.09657776, 19.31741128, 17.8773226,
               14.61725263, 7.933140153, 1.04889534, -0.643180503]
diff_values = [-0.176682705, -0.173638556, -0.101247371, -0.205385989, -0.090897953, -0.177227694, -0.177181869, -0.283154672,
               -0.347464124, -0.461201152, -0.287004448, -0.253326465]

# Run function
plot_dual_axis_chart(days, kymn_values, coop_values, diff_values)
#=================================================================================================================================================================================
#06262025 KYMNCOOP TMAX BY WSPD CAT ADDED standard error 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from statsmodels.stats.multitest import multipletests

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\ANOM.csv')

# Ensure numeric types
df['Tmax'] = pd.to_numeric(df['Tmax'], errors='coerce')
df['SRAD'] = pd.to_numeric(df['SRAD'], errors='coerce')
df['WSPD'] = pd.to_numeric(df['WSPD'], errors='coerce')

# Convert date
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
else:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected']).dt.date

# Original bin assignment
def assign_bin(WSPD, SRAD):
    if WSPD == 0 and SRAD <= 400:
        return "CATA"
    elif 0 < WSPD <= 2 and SRAD <= 400:
        return "CATB"
    elif WSPD > 2 and SRAD <= 400:
        return "CATC"
    elif WSPD == 0 and SRAD > 400:
        return "CATD"
    elif 0 < WSPD <= 2 and SRAD > 400:
        return "CATE"
    elif WSPD > 2 and SRAD > 400:
        return "CATF"
    else:
        return "NO CAT"

# Apply original binning
df['SRAD_Bin'] = df.apply(lambda row: assign_bin(row['WSPD'], row['SRAD']), axis=1)

# Set order
bin_order = ["CATA", "CATB", "CATC", "CATD", "CATE", "CATF"]
df['SRAD_Bin'] = pd.Categorical(df['SRAD_Bin'], categories=bin_order, ordered=True)

# Remove uncategorized
df = df[df['SRAD_Bin'].notna()]

# Merge bins
def merge_bins(cat):
    if cat in ['CATA', 'CATB']:
        return 'CAT1'
    elif cat == 'CATC':
        return 'CAT2'
    elif cat in ['CATD', 'CATE']:
        return 'CAT3'
    elif cat == 'CATF':
        return 'CAT4'
    else:
        return 'NO CAT'

# Apply merging
df['Merged_Bin'] = df['SRAD_Bin'].apply(merge_bins)
new_bin_order = ['CAT1', 'CAT2', 'CAT3', 'CAT4']
df['Merged_Bin'] = pd.Categorical(df['Merged_Bin'], categories=new_bin_order, ordered=True)

# Filter again
df_filtered = df[df['Merged_Bin'].notna()]

# Group statistics
average_diff_merged = df_filtered.groupby('Merged_Bin', observed=True)['Tmax'].mean()
bin_counts_merged = df_filtered.groupby('Merged_Bin', observed=True)['Tmax'].count()
std_dev_merged = df_filtered.groupby('Merged_Bin', observed=True)['Tmax'].std()
median_diff_merged = df_filtered.groupby('Merged_Bin', observed=True)['Tmax'].median()

# Summary table
category_stats_merged = df_filtered.groupby('Merged_Bin', observed=True)['Tmax'].agg(
    Mean_Difference='mean',
    Median_Difference='median',
    Std_Deviation='std',
    Count='count'
).reindex(new_bin_order)

print("Merged Category Stats:\n", category_stats_merged)
category_stats_merged['Std_Error'] = category_stats_merged['Std_Deviation'] / np.sqrt(category_stats_merged['Count'])
# Welch’s t-tests
categories_merged = df_filtered['Merged_Bin'].cat.categories
merged_results = []

for i in range(len(categories_merged)):
    for j in range(i + 1, len(categories_merged)):
        cat1, cat2 = categories_merged[i], categories_merged[j]
        group1 = df_filtered[df_filtered['Merged_Bin'] == cat1]['Tmax'].dropna()
        group2 = df_filtered[df_filtered['Merged_Bin'] == cat2]['Tmax'].dropna()
        if len(group1) > 1 and len(group2) > 1:
            t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=False)
            merged_results.append({
                'Comparison': f'{cat1} vs {cat2}',
                't-statistic': t_stat,
                'p-value': p_val
            })

# Bonferroni correction
t_test_merged_df = pd.DataFrame(merged_results)
_, pvals_corr_merged, _, _ = multipletests(t_test_merged_df['p-value'], method='bonferroni')
t_test_merged_df['p-value (Bonferroni corrected)'] = pvals_corr_merged
t_test_merged_df['Significant (p < 0.05)'] = t_test_merged_df['p-value (Bonferroni corrected)'] < 0.05

# Show results
print("\nMerged Welch's t-test Results:")
print(t_test_merged_df)
print(category_stats_merged['Std_Error'])
# Plotting
plt.figure(figsize=(8, 4))
ax = average_diff_merged.plot(
    kind='bar',
    yerr=std_dev_merged,
    capsize=4,
    color='#FF6666',
    edgecolor='black',
    error_kw=dict(ecolor='black', lw=1)
)

# Annotate with counts
for i, (val, count) in enumerate(zip(average_diff_merged, bin_counts_merged)):
    offset = 0.2 if val >= 0 else -0.4
    va = 'bottom' if val >= 0 else 'top'
    ax.text(i, val + offset, f'{count}', ha='center', va=va, fontsize=14)

plt.xlabel('WSPD + SRAD Categories', fontsize=16)
plt.ylabel('Avg (KYMN-COOP) Tmax (°C)', fontsize=12)
plt.grid(True, axis='y')
plt.xticks(rotation=0, fontsize=13)
plt.yticks(fontsize=13)
plt.ylim(-2, 2)
plt.yticks(range(-2, 3, 1))
plt.tight_layout()
plt.show()
#=================================================================================================================================================================================
#06262025 KYMNASOS TMAX BY WSPD CAT ADDED standard error 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from statsmodels.stats.multitest import multipletests

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\ANOMA.csv')

# Ensure numeric types
df['Tmax'] = pd.to_numeric(df['Tmax'], errors='coerce')
df['SRAD'] = pd.to_numeric(df['SRAD'], errors='coerce')
df['WSPD'] = pd.to_numeric(df['WSPD'], errors='coerce')

# Convert date
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
else:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected']).dt.date

# Original bin assignment
def assign_bin(WSPD, SRAD):
    if WSPD == 0 and SRAD <= 400:
        return "CATA"
    elif 0 < WSPD <= 2 and SRAD <= 400:
        return "CATB"
    elif WSPD > 2 and SRAD <= 400:
        return "CATC"
    elif WSPD == 0 and SRAD > 400:
        return "CATD"
    elif 0 < WSPD <= 2 and SRAD > 400:
        return "CATE"
    elif WSPD > 2 and SRAD > 400:
        return "CATF"
    else:
        return "NO CAT"

# Apply original binning
df['SRAD_Bin'] = df.apply(lambda row: assign_bin(row['WSPD'], row['SRAD']), axis=1)

# Set order
bin_order = ["CATA", "CATB", "CATC", "CATD", "CATE", "CATF"]
df['SRAD_Bin'] = pd.Categorical(df['SRAD_Bin'], categories=bin_order, ordered=True)

# Remove uncategorized
df = df[df['SRAD_Bin'].notna()]

# Merge bins
def merge_bins(cat):
    if cat in ['CATA', 'CATB']:
        return 'CAT1'
    elif cat == 'CATC':
        return 'CAT2'
    elif cat in ['CATD', 'CATE']:
        return 'CAT3'
    elif cat == 'CATF':
        return 'CAT4'
    else:
        return 'NO CAT'

# Apply merging
df['Merged_Bin'] = df['SRAD_Bin'].apply(merge_bins)
new_bin_order = ['CAT1', 'CAT2', 'CAT3', 'CAT4']
df['Merged_Bin'] = pd.Categorical(df['Merged_Bin'], categories=new_bin_order, ordered=True)

# Filter again
df_filtered = df[df['Merged_Bin'].notna()]

# Group statistics
average_diff_merged = df_filtered.groupby('Merged_Bin', observed=True)['Tmax'].mean()
bin_counts_merged = df_filtered.groupby('Merged_Bin', observed=True)['Tmax'].count()
std_dev_merged = df_filtered.groupby('Merged_Bin', observed=True)['Tmax'].std()
median_diff_merged = df_filtered.groupby('Merged_Bin', observed=True)['Tmax'].median()


# Summary table
category_stats_merged = df_filtered.groupby('Merged_Bin', observed=True)['Tmax'].agg(
    Mean_Difference='mean',
    Median_Difference='median',
    Std_Deviation='std',
    Count='count'
).reindex(new_bin_order)

print("Merged Category Stats:\n", category_stats_merged)
category_stats_merged['Std_Error'] = category_stats_merged['Std_Deviation'] / np.sqrt(category_stats_merged['Count'])

# Welch’s t-tests
categories_merged = df_filtered['Merged_Bin'].cat.categories
merged_results = []

for i in range(len(categories_merged)):
    for j in range(i + 1, len(categories_merged)):
        cat1, cat2 = categories_merged[i], categories_merged[j]
        group1 = df_filtered[df_filtered['Merged_Bin'] == cat1]['Tmax'].dropna()
        group2 = df_filtered[df_filtered['Merged_Bin'] == cat2]['Tmax'].dropna()
        if len(group1) > 1 and len(group2) > 1:
            t_stat, p_val = stats.ttest_ind(group1, group2, equal_var=False)
            merged_results.append({
                'Comparison': f'{cat1} vs {cat2}',
                't-statistic': t_stat,
                'p-value': p_val
            })

# Bonferroni correction
t_test_merged_df = pd.DataFrame(merged_results)
_, pvals_corr_merged, _, _ = multipletests(t_test_merged_df['p-value'], method='bonferroni')
t_test_merged_df['p-value (Bonferroni corrected)'] = pvals_corr_merged
t_test_merged_df['Significant (p < 0.05)'] = t_test_merged_df['p-value (Bonferroni corrected)'] < 0.05

# Show results
print("\nMerged Welch's t-test Results:")
print(t_test_merged_df)
print(category_stats_merged['Std_Error'])
# Plotting
plt.figure(figsize=(8, 4))
ax = average_diff_merged.plot(
    kind='bar',
    yerr=std_dev_merged,
    capsize=4,
    color='#FF6666',
    edgecolor='black',
    error_kw=dict(ecolor='black', lw=1)
)

# Annotate with counts
for i, (val, count) in enumerate(zip(average_diff_merged, bin_counts_merged)):
    offset = 0.2 if val >= 0 else -0.4
    va = 'bottom' if val >= 0 else 'top'
    ax.text(i, val + offset, f'{count}', ha='center', va=va, fontsize=14)

plt.xlabel('WSPD + SRAD Categories', fontsize=16)
plt.ylabel('Avg (KYMN-ASOS) Tmax (°C)', fontsize=12)
plt.tick_params(axis='both', labelsize=24)
plt.grid(True, axis='y')
plt.xticks(rotation=0, fontsize=13)
plt.yticks(fontsize=13)
plt.ylim(-2, 2)
plt.tight_layout()
plt.show()
#=================================================================================================================================================================================
#07182025 ALL CORRELATION OF TEMP BY DISTANCE     (CORRELATIONS OF DAILY MEAN TEMP DIFF OF PAIRED STATIONS WITH DISTANCE)
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker
import numpy as np

# Define all datasets
data1 = {
    'KYMN': ['SCTV', 'RSVL', 'BTCK', 'MRHD', 'MROK', 'GRHM', 'ELST', 'FCHV', 'FRNY', 'SCTV', 'BNVL', 'CRMT', 'BLRK'],
    'COOP': ['SCTK2', 'RUSK2', 'PNVK2', 'CRLK2', 'BRRK2', 'HNDK2', 'CSYK2', 'TVLK2', 'HNDK2', 'BRRK2', 'BCAK2', 'LMK', 'NOLK2'],
    'Distance': [1.23, 2.88, 8.48, 11.76, 12.83, 14.05, 16.22, 16.98, 18.88, 18.92, 20.40, 21.40, 21.59],
    'Correlation_Tmax': [0.997, 0.987, 0.995, 0.994, 0.987, 0.996, 0.996, 0.993, 0.995, 0.986, 0.988, 0.997, 0.982]
}

data2 = {
    'KYMN': ['FARM', 'LSML', 'HUEY', 'LXGN', 'HHTS', 'PVRT'],
    'COOP': ['BWG', 'FFT', 'CVG', 'LEX', 'CVG', 'OWB'],
    'Distance': [5.89, 7.86, 9.50, 9.68, 17.18, 21.61],
    'Correlation_Tmax': [0.999, 0.999, 0.997, 0.997, 0.997, 0.997]
}

data3 = {
    'KYMN': ['SCTV', 'RSVL', 'BTCK', 'MRHD', 'MROK', 'GRHM', 'ELST', 'FCHV', 'FRNY', 'SCTV', 'BNVL', 'CRMT', 'BLRK'],
    'COOP': ['SCTK2', 'RUSK2', 'PNVK2', 'CRLK2', 'BRRK2', 'HNDK2', 'CSYK2', 'TVLK2', 'HNDK2', 'BRRK2', 'BCAK2', 'LMK', 'NOLK2'],
    'Distance': [1.23, 2.88, 8.48, 11.76, 12.83, 14.05, 16.22, 16.98, 18.88, 18.92, 20.40, 21.40, 21.59],
    'Correlation_Tmin': [0.994, 0.987, 0.992, 0.987, 0.985, 0.989, 0.991, 0.988, 0.995, 0.983, 0.968, 0.991, 0.984]
}

data4 = {
    'KYMN': ['FARM', 'LSML', 'HUEY', 'LXGN', 'HHTS', 'PVRT'],
    'COOP': ['BWG', 'FFT', 'CVG', 'LEX', 'CVG', 'OWB'],
    'Distance': [5.89, 7.86, 9.50, 9.68, 17.18, 21.61],
    'Correlation_Tmin': [0.996, 0.997, 0.993, 0.993, 0.994, 0.988]
}

# Create DataFrames
df_tmax_coop = pd.DataFrame(data1)
df_tmax_asos = pd.DataFrame(data2)
df_tmin_coop = pd.DataFrame(data3)
df_tmin_asos = pd.DataFrame(data4)

# Initialize the plot
plt.figure(figsize=(8, 4))

# Plot Tmax datasets
plt.scatter(df_tmax_coop['Distance'], df_tmax_coop['Correlation_Tmax'],
            color='red', s=140, alpha=0.7, label='KYMN–COOP (Tmax)')
plt.scatter(df_tmax_asos['Distance'], df_tmax_asos['Correlation_Tmax'],
            color='red', s=140, alpha=0.7, marker='s', label='KYMN–ASOS (Tmax)')

# Plot Tmin datasets
plt.scatter(df_tmin_coop['Distance'], df_tmin_coop['Correlation_Tmin'],
            color='blue', s=80, alpha=0.7, label='KYMN–COOP (Tmin)')
plt.scatter(df_tmin_asos['Distance'], df_tmin_asos['Correlation_Tmin'],
            color='blue', s=80, alpha=0.7, marker='s', label='KYMN–ASOS (Tmin)')

# Annotate Tmax points
for i, row in df_tmax_coop.iterrows(): 
    plt.annotate(f"{row['KYMN']}-{row['COOP']}",
                 (row['Distance'], row['Correlation_Tmax']),
                 fontsize=8, ha='right', va='bottom')

for i, row in df_tmax_asos.iterrows():
    plt.annotate(f"{row['KYMN']}-{row['COOP']}",
                 (row['Distance'], row['Correlation_Tmax']),
                 fontsize=8, ha='left', va='top')

# Annotate Tmin points
for i, row in df_tmin_coop.iterrows(): 
    plt.annotate(f"{row['KYMN']}-{row['COOP']}",
                 (row['Distance'], row['Correlation_Tmin']),
                 fontsize=8, ha='right', va='bottom')

for i, row in df_tmin_asos.iterrows():
    plt.annotate(f"{row['KYMN']}-{row['COOP']}",
                 (row['Distance'], row['Correlation_Tmin']),
                 fontsize=8, ha='left', va='top')

# Axis labels and formatting
plt.xlabel('Distance (km)', fontsize=14)
plt.ylabel('Correlation coefficient', fontsize=14)
#plt.ylim(0.96, 1.001)
#plt.yticks(np.arange(0.97, 1.01, 0.01))
plt.yticks([0.97, 0.98, 0.99, 1.00])
plt.gca().yaxis.set_major_formatter(mticker.FormatStrFormatter('%.2f'))

# Grid, legend, layout
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(fontsize=12)
plt.tight_layout()
plt.show()

# Optional: Save to file
# plt.savefig('Tmax_Tmin_correlation_vs_distance_labeled.png', dpi=300, bbox_inches='tight')
#=================================================================================================================================================================================
#07212025 YEARLY MEDIAN TMAX PLOT KYMNASOS
import pandas as pd
import matplotlib.pyplot as plt

# ------------------------------
# 1. Create the DataFrame
# ------------------------------

data = {
    'Years': [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020],
    'FARM-BWG': [-1.03507, -1.19209, -0.90997, -0.58568, -1.02789, -1.06716, -0.95413, -0.94436, -0.96879, -0.82067],
    'LSML-FFT': [-0.10287, -0.23261, -0.13799, -0.17976, -0.16709, -0.53398, -0.78633, -0.80341, -0.86215, -0.91585],
    'HUEY-CVG': [-0.52292, -0.61220, -0.54138, -0.72855, -0.73131, -0.62897, -0.67454, -0.72106, -0.80211, -0.75530],
    'LXGN-LEX': [-0.44209, -0.56263, -1.13182, -1.40483, -0.96186, -1.17292, -1.24724, -1.22810, -1.64833, -0.30687],
    'HHTS-CVG': [-0.41148, -0.63145, -0.47124, -0.44371, -0.66556, -0.46839, -0.54637, -0.45192, -0.67254, -0.52772],
    'PVRT-OWB': [-0.0928, -0.2913, -0.3490, -0.0688, -0.3978, -0.3759, -0.42738, -0.33916, -0.53891, -0.55318]
}


df = pd.DataFrame(data)

# ------------------------------
# 2. Plot Each Station Pair
# ------------------------------
plt.figure(figsize=(8, 5))

for col in df.columns[1:]:  # Skip the 'Years' column
    plt.plot(df['Years'], df[col], marker='o', label=col)

#plt.title("Yearly Median KYMN–ASOS Tmax Differences", fontsize=18)
plt.xlabel("Year", fontsize=18)
plt.ylabel("Median Difference in Tmax (°C)", fontsize=18)

# Increase font size for x-axis tick labels (years)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.ylim(-3, 3) 
plt.legend(loc='upper right', fontsize=12, ncol=2)
plt.tight_layout()
plt.show()
#=================================================================================================================================================================================
#07212025 YEARLY MEDIAN TMAX PLOT KYMNCOOP 
import pandas as pd
import matplotlib.pyplot as plt

# ------------------------------
# 1. Create the DataFrame
# ------------------------------
data = {
    'Years': [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020],
    'SCTV-SCTK2': [-0.18, -0.25, -0.25, -0.20, -0.34, -0.16, 0.03, 0.04, 0.05, -0.06],
    'RSVL-RUSK2': [0.02, -0.16, 0.00, -0.43, -0.41, -0.37, -0.26, -0.38, -0.12, -0.15],
    'BTCK-PNVK2': [0.21, 0.26, 0.31, 0.27, 0.27, 0.34, 0.07, 0.04, 0.08, 0.05],
    'MRHD-CRLK2': [-0.70, -1.16, -1.21, -0.42, -0.10, 0.04, 0.06, -0.06, -0.10, -0.19],
    'MROK-BRRK2': [-2.15, -0.95, -0.36, -0.85, -1.44, -1.39, -0.75, -0.72, -0.74, -0.66],
    'GRHM-HNDK2': [-0.13, -0.22, -0.19, -0.30, -0.30, -0.31, -0.19, -0.16, -0.14, -0.04],
    'ELST-CSYK2': [-0.26, -0.44, -0.21, -0.18, -0.29, -0.35, -0.18, -0.16, -0.02, -0.17],
    'FCHV-TVLK2': [-1.78, -2.11, -2.22, -2.49, -2.25, -2.32, -2.41, -2.62, -2.86, -2.76],
    'FRNY-HNDK2': [-0.15, 0.01, -0.08, 0.01, 0.01, -0.01, 0.01, 0.09, 0.07, 0.42],
    'SCTV-BRRK2': [-1.71, -0.70, -0.19, -0.61, -1.29, -1.04, -0.37, -0.22, -0.36, -0.37],
    'BNVL-BCAK2': [0.82, 0.75, 0.98, 0.93, 1.17, 1.13, 1.04, 1.13, 1.41, 1.40],
    'CRMT-LMK': [-0.19, -0.30, -0.29, -0.24, 0.44, 0.34, -0.01, 0.04, 0.07, 0.04],
    'BLRK-NOLK2': [-2.37, -2.93, -1.86, -1.22, -1.29, -2.50, -2.19, -1.93, -2.10, -1.70]
}

df = pd.DataFrame(data)

# ------------------------------
# 2. Plot Each Station Pair
# ------------------------------
plt.figure(figsize=(10, 6))

for col in df.columns[1:]:  # Skip the 'Years' column
    plt.plot(df['Years'], df[col], marker='o', label=col)

#plt.title("Yearly Median KYMNCOOP Tmax Differences", fontsize=18)
plt.xlabel("Year", fontsize=18)
plt.ylabel("Median Difference in Tmax (°C)", fontsize=18)

# Increase font size for x-axis tick labels (years)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.ylim(-3, 3) 
plt.legend(loc='upper right', fontsize=10, ncol=5)
plt.tight_layout()
plt.show()
#=================================================================================================================================================================================
#07212025 YEARLY MEDIAN TMIN PLOT KYMNASOS
import pandas as pd
import matplotlib.pyplot as plt

# ------------------------------
# 1. Create the DataFrame
# ------------------------------

data = {
    'Years': [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020],
    'FARM-BWG': [-0.71396, -1.00146, -0.50231, -0.52025, -0.59799, -0.77488, -0.59809, -0.79717, -0.86857, -1.02670],
    'LSML-FFT': [0.01366, -0.08971, 0.05576, -0.01087, -0.05764, -0.50494, -0.47547, -0.48367, -0.52134, -0.43308],
    'HUEY-CVG': [0.05740, 0.19219, -0.03552, -0.10390, 0.11538, 0.13793, 0.13109, -0.06691, -0.13524, -0.20437],
    'LXGN-LEX': [0.21047, 0.47668, -0.13754, -0.26138, 0.24409, 0.03003, -0.14310, -0.24863, -0.33900, 0.61242],
    'HHTS-CVG': [0.13881, 0.46034, 0.11957, 0.13328, 0.09784, 0.06830, 0.04835, -0.10562, -0.10099, -0.05215],
    'PVRT-OWB': [-0.87810, -1.98490, -0.98938, -0.83310, -1.07790, -0.87470, -1.05364, -0.91823, -0.86339, -1.11383]
}

df = pd.DataFrame(data)

# ------------------------------
# 2. Plot Each Station Pair
# ------------------------------
plt.figure(figsize=(8, 5))

for col in df.columns[1:]:  # Skip the 'Years' column
    plt.plot(df['Years'], df[col], marker='o', label=col)

#plt.title("Yearly Median KYMN–ASOS Tmin Differences", fontsize=18)
plt.xlabel("Year", fontsize=18)
plt.ylabel("Median Difference in Tmin (°C)", fontsize=18)

# Increase font size for x-axis tick labels (years)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.ylim(-3, 3) 
plt.legend(loc='upper right', fontsize=12, ncol=2)
plt.tight_layout()
plt.show()
#=================================================================================================================================================================================
#07212025 YEARLY MEDIAN TMIN PLOT KYMNCOOP 
import pandas as pd
import matplotlib.pyplot as plt

# ------------------------------
# 1. Create the DataFrame
# ------------------------------

data = {
    'Years': [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020],
    'SCTV-SCTK2': [0.7901, 0.8655, 0.6909, 0.5507, 0.3355, 0.6808, 0.7724, 0.7381, 0.9270, 0.8148],
    'RSVL-RUSK2': [0.0609, 0.1720, 0.0023, -0.3078, -0.2013, -0.1271, -0.1173, -0.1647, 0.0970, 0.1007],
    'BTCK-PNVK2': [-1.1371, -1.3508, -1.2718, -0.8273, -1.0302, -1.1071, -0.9959, -0.8325, -1.1014, -0.9846],
    'MRHD-CRLK2': [0.6170, 0.7695, -0.7577, -0.6798, -0.6742, -0.5012, -0.6543, -0.2268, -0.4518, -0.5385],
    'MROK-BRRK2': [0.5175, 0.6280, 0.4746, 0.6076, 0.9293, 2.1160, -0.1217, -0.2300, 0.0407, -0.0086],
    'GRHM-HNDK2': [-0.8987, -1.3604, -0.8585, -1.0090, -1.0743, -0.9818, -1.3871, -0.7449, -1.1384, -1.2607],
    'ELST-CSYK2': [-0.0392, -0.0633, 0.1140, 0.0624, 0.1188, -0.0272, -0.0336, 0.1030, 0.0471, -0.0602],
    'FCHV-TVLK2': [1.7620, 2.2648, 0.4967, 0.5495, 0.5114, 0.4093, 0.4128, 0.0855, 0.7306, 1.9236],
    'FRNY-HNDK2': [-0.1567, -0.2221, -0.2652, -0.3189, -0.3403, -0.3725, -0.3533, -0.2377, -0.3149, -0.3277],
    'SCTV-BRRK2': [0.9597, 1.0548, 0.7487, 0.7863, 1.0042, 2.3941, 0.1299, 0.0692, 0.2918, 0.3883],
    'BNVL-BCAK2': [-0.3872, -0.8416, -0.3870, -0.5282, -0.6795, -0.6391, -0.8020, -0.6596, -0.8036, -0.6995],
    'CRMT-LMK': [-0.6003, -1.0229, -0.7010, -0.9581, -0.4006, -0.8680, -0.8359, -0.5129, -0.8208, -0.9728],
    'BLRK-NOLK2': [-0.0386, -0.1610, -0.1369, 0.0598, 0.0500, 0.1832, 0.1889, 0.2985, -0.0097, -0.3240]
}
df = pd.DataFrame(data)

# ------------------------------
# 2. Plot Each Station Pair
# ------------------------------
plt.figure(figsize=(10, 6))

for col in df.columns[1:]:  # Skip the 'Years' column
    plt.plot(df['Years'], df[col], marker='o', label=col)

#plt.title("Yearly Median KYMNCOOP Tmin Differences", fontsize=18)
plt.xlabel("Year", fontsize=18)
plt.ylabel("Median Difference in Tmin (°C)", fontsize=18)

# Increase font size for x-axis tick labels (years)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.ylim(-3, 3) 
plt.legend(loc='upper right', fontsize=9, ncol=5)
plt.tight_layout()
plt.show()
#=================================================================================================================================================================================
#07302025  HEAT MAP KYMN-COOP T-MAX SAME LEGEND
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\ALL_2\ANOM.csv')

# Ensure necessary columns are numeric
df['Tmax'] = pd.to_numeric(df['Tmax'], errors='coerce')
df['SRAD'] = pd.to_numeric(df['SRAD'], errors='coerce')
df['WSPD'] = pd.to_numeric(df['WSPD'], errors='coerce')

# Convert the 'Date' column to datetime
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
else:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected']).dt.date

# Define the 9-category bin assignment function
def assign_bin(WSPD, SRAD):
    if WSPD < 2:
        if SRAD < 200:
            return "CAT1"
        elif 200 <= SRAD <= 500:
            return "CAT2"
        elif SRAD > 500:
            return "CAT3"
    elif 2 <= WSPD <= 5:
        if SRAD < 200:
            return "CAT4"
        elif 200 <= SRAD <= 500:
            return "CAT5"
        elif SRAD > 500:
            return "CAT6"
    elif WSPD > 5:
        if SRAD < 200:
            return "CAT7"
        elif 200 <= SRAD <= 500:
            return "CAT8"
        elif SRAD > 500:
            return "CAT9"
    else:
        return "NO CAT"

# Apply bin assignment
df['Category'] = df.apply(lambda row: assign_bin(row['WSPD'], row['SRAD']), axis=1)

# Define bin order and assign as ordered category
bin_order = ["CAT1", "CAT2", "CAT3", "CAT4", "CAT5", "CAT6", "CAT7", "CAT8", "CAT9"]
df['Category'] = pd.Categorical(df['Category'], categories=bin_order, ordered=True)

# Compute average Tmax and sample size per category
average_diff_per_bin = df.groupby('Category', observed=True)['Tmax'].mean()
bin_counts = df.groupby('Category', observed=True)['Tmax'].count()

# Plot bar chart of average Tmax per category
plt.figure(figsize=(8, 4))
ax = average_diff_per_bin.plot(kind='bar', color='#FF6666', edgecolor='black')

# Add sample count annotations
for i, (val, count) in enumerate(zip(average_diff_per_bin, bin_counts)):
    offset = 0.2 if val >= 0 else -0.4
    va = 'bottom' if val >= 0 else 'top'
    ax.text(i, val + offset, f'{count}', ha='center', va=va, fontsize=13)

plt.ylabel('Avg (KYMN-COOP) Tmax (°C)', fontsize=12)
plt.xlabel('Category', fontsize=14)
plt.grid(True, axis='y')
plt.xticks(rotation=0, fontsize=13)
plt.yticks(fontsize=13)
plt.ylim(-2, 2)
plt.yticks(range(-2, 3, 1))
plt.tight_layout()
plt.show()

# ------------------- 3x3 Matrix Section -------------------

# Define wind speed and solar radiation bin labels
def ws_bin(wspd):
    if wspd < 2:
        return '<2 m/s'
    elif 2 <= wspd <= 5:
        return '2-5 m/s'
    else:
        return '>5 m/s'

def sr_bin(srad):
    if srad < 200:
        return '<200 W/m²'
    elif 200 <= srad <= 500:
        return '200-500 W/m²'
    else:
        return '>500 W/m²'

# Apply bin labels
df['WSPD_bin'] = df['WSPD'].apply(ws_bin)
df['SRAD_bin'] = df['SRAD'].apply(sr_bin)

# Define sort order
ws_order = ['<2 m/s', '2-5 m/s', '>5 m/s']
sr_order = ['<200 W/m²', '200-500 W/m²', '>500 W/m²']

# Convert to ordered categorical
df['WSPD_bin'] = pd.Categorical(df['WSPD_bin'], categories=ws_order, ordered=True)
df['SRAD_bin'] = pd.Categorical(df['SRAD_bin'], categories=sr_order, ordered=True)

# Create pivot tables
pivot_avg = df.pivot_table(values='Tmax', index='WSPD_bin', columns='SRAD_bin', aggfunc='mean')
pivot_counts = df.pivot_table(values='Tmax', index='WSPD_bin', columns='SRAD_bin', aggfunc='count')

# Display results
print("\n=== Average Tmax (°C) by WSPD and SRAD bins (Ordered) ===")
print(pivot_avg.round(2))

print("\n=== Sample Counts by WSPD and SRAD bins (Ordered) ===")
print(pivot_counts)

# Export average Tmax matrix to CSV
#pivot_avg.to_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\pivot_avg_Tmax.csv')
# Export count matrix to CSV
#pivot_counts.to_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\pivot_count_Tmax.csv')


# Plot heatmap of average Tmax
plt.figure(figsize=(8, 6))
sns.heatmap(pivot_avg, annot=True, fmt=".2f", cmap="coolwarm_r", linewidths=0.5, 
            linecolor='gray', vmin=-1.8, vmax=1.8, cbar_kws={'label': 'Avg (KYMN-COOP) Tmax (°C)', 'ticks': 
                                                              np.arange(-1.8, 1.81, 0.6)})


#plt.title('Average Tmax (°C) Difference by Wind Speed and Solar Radiation', fontsize=12)

plt.xlabel('Solar Radiation Bin', fontsize=12)
plt.ylabel('Wind Speed Bin', fontsize=12)
plt.xticks(rotation=0)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()
#=================================================================================================================================================================================
#07302025 HEAT MAP KYMN-ASOS T-MAX SAME LEGEND
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\ALL_2\ANOMA.csv')

# Ensure necessary columns are numeric
df['Tmax'] = pd.to_numeric(df['Tmax'], errors='coerce')
df['SRAD'] = pd.to_numeric(df['SRAD'], errors='coerce')
df['WSPD'] = pd.to_numeric(df['WSPD'], errors='coerce')

# Convert the 'Date' column to datetime
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
else:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected']).dt.date

# Define the 9-category bin assignment function
def assign_bin(WSPD, SRAD):
    if WSPD < 2:
        if SRAD < 200:
            return "CAT1"
        elif 200 <= SRAD <= 500:
            return "CAT2"
        elif SRAD > 500:
            return "CAT3"
    elif 2 <= WSPD <= 5:
        if SRAD < 200:
            return "CAT4"
        elif 200 <= SRAD <= 500:
            return "CAT5"
        elif SRAD > 500:
            return "CAT6"
    elif WSPD > 5:
        if SRAD < 200:
            return "CAT7"
        elif 200 <= SRAD <= 500:
            return "CAT8"
        elif SRAD > 500:
            return "CAT9"
    else:
        return "NO CAT"

# Apply bin assignment
df['Category'] = df.apply(lambda row: assign_bin(row['WSPD'], row['SRAD']), axis=1)

# Define bin order and assign as ordered category
bin_order = ["CAT1", "CAT2", "CAT3", "CAT4", "CAT5", "CAT6", "CAT7", "CAT8", "CAT9"]
df['Category'] = pd.Categorical(df['Category'], categories=bin_order, ordered=True)

# Compute average Tmax and sample size per category
average_diff_per_bin = df.groupby('Category', observed=True)['Tmax'].mean()
bin_counts = df.groupby('Category', observed=True)['Tmax'].count()

# Plot bar chart of average Tmax per category
plt.figure(figsize=(8, 4))
ax = average_diff_per_bin.plot(kind='bar', color='#FF6666', edgecolor='black')

# Add sample count annotations
for i, (val, count) in enumerate(zip(average_diff_per_bin, bin_counts)):
    offset = 0.2 if val >= 0 else -0.4
    va = 'bottom' if val >= 0 else 'top'
    ax.text(i, val + offset, f'{count}', ha='center', va=va, fontsize=13)

plt.ylabel('Avg (KYMN-ASOS) Tmax (°C)', fontsize=12)
plt.xlabel('Category', fontsize=14)
plt.grid(True, axis='y')
plt.xticks(rotation=0, fontsize=13)
plt.yticks(fontsize=13)
plt.ylim(-2, 2)
plt.yticks(range(-2, 3, 1))
plt.tight_layout()
plt.show()

# ------------------- 3x3 Matrix Section -------------------

# Define wind speed and solar radiation bin labels
def ws_bin(wspd):
    if wspd < 2:
        return '<2 m/s'
    elif 2 <= wspd <= 5:
        return '2-5 m/s'
    else:
        return '>5 m/s'

def sr_bin(srad):
    if srad < 200:
        return '<200 W/m²'
    elif 200 <= srad <= 500:
        return '200-500 W/m²'
    else:
        return '>500 W/m²'

# Apply bin labels
df['WSPD_bin'] = df['WSPD'].apply(ws_bin)
df['SRAD_bin'] = df['SRAD'].apply(sr_bin)

# Define sort order
ws_order = ['<2 m/s', '2-5 m/s', '>5 m/s']
sr_order = ['<200 W/m²', '200-500 W/m²', '>500 W/m²']

# Convert to ordered categorical
df['WSPD_bin'] = pd.Categorical(df['WSPD_bin'], categories=ws_order, ordered=True)
df['SRAD_bin'] = pd.Categorical(df['SRAD_bin'], categories=sr_order, ordered=True)

# Create pivot tables
pivot_avg = df.pivot_table(values='Tmax', index='WSPD_bin', columns='SRAD_bin', aggfunc='mean')
pivot_counts = df.pivot_table(values='Tmax', index='WSPD_bin', columns='SRAD_bin', aggfunc='count')

# Display results
print("\n=== Average Tmax (°C) by WSPD and SRAD bins (Ordered) ===")
print(pivot_avg.round(2))

print("\n=== Sample Counts by WSPD and SRAD bins (Ordered) ===")
print(pivot_counts)

# Export average Tmax matrix to CSV
#pivot_avg.to_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\pivot_avg_Tmax.csv')
# Export count matrix to CSV
#pivot_counts.to_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\pivot_count_Tmax.csv')


# Plot heatmap of average Tmax
plt.figure(figsize=(8, 6))
sns.heatmap(pivot_avg, annot=True, fmt=".2f", cmap="coolwarm_r", linewidths=0.5, 
            linecolor='gray', vmin=-1.8, vmax=1.8, cbar_kws={'label': 'Avg (KYMN-ASOS) Tmax (°C)', 'ticks': 
                                                              np.arange(-1.8, 1.81, 0.6)})



#plt.title('Average Tmax (°C) Difference by Wind Speed and Solar Radiation', fontsize=12)

plt.xlabel('Solar Radiation Bin', fontsize=12)
plt.ylabel('Wind Speed Bin', fontsize=12)
plt.xticks(rotation=0)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()
#=================================================================================================================================================================================
#07302025 HEAT MAP KYMN-ASOS T-MIN SAME LEGEND
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\Tmin\KYMNASOS_Tmin_SRAD_WSPD.csv')

# Ensure necessary columns are numeric
df['Tmin'] = pd.to_numeric(df['Tmin'], errors='coerce')
df['SRAD'] = pd.to_numeric(df['SRAD'], errors='coerce')
df['WSPD'] = pd.to_numeric(df['WSPD'], errors='coerce')

# Convert the 'Date' column to datetime
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
else:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected']).dt.date    
    
def assign_category(WSPD, SRAD):
    if WSPD < 2:
        if SRAD < 200:
            return "CAT1"
        elif 200 <= SRAD <= 500:
            return "CAT2"
    elif 2 <= WSPD <= 5:
        if SRAD < 200:
            return "CAT3"
        elif 200 <= SRAD <= 500:
            return "CAT4"
    elif WSPD > 5:
        if SRAD < 200:
            return "CAT5"
        elif 200 <= SRAD <= 500:
            return "CAT6"
    return "NO CAT"

# Apply bin assignment
df['Category'] = df.apply(lambda row: assign_category(row['WSPD'], row['SRAD']), axis=1)

# Define bin order and assign as ordered category
bin_order = ["CAT1", "CAT2", "CAT3", "CAT4", "CAT5", "CAT6"]
df['Category'] = pd.Categorical(df['Category'], categories=bin_order, ordered=True)

# Compute average Tmax and sample size per category
average_diff_per_bin = df.groupby('Category', observed=True)['Tmin'].mean()
bin_counts = df.groupby('Category', observed=True)['Tmin'].count()

# Plot bar chart of average Tmax per category
plt.figure(figsize=(8, 4))
ax = average_diff_per_bin.plot(kind='bar', color='blue', edgecolor='black')

# Add sample count annotations
for i, (val, count) in enumerate(zip(average_diff_per_bin, bin_counts)):
    offset = 0.2 if val >= 0 else -0.4
    va = 'bottom' if val >= 0 else 'top'
    ax.text(i, val + offset, f'{count}', ha='center', va=va, fontsize=13)

plt.ylabel('Avg (KYMN-ASOS) Tmin (°C)', fontsize=12)
plt.xlabel('Category', fontsize=14)
plt.grid(True, axis='y')
plt.xticks(rotation=0, fontsize=13)
plt.yticks(fontsize=13)
plt.ylim(-2, 2)
plt.yticks(range(-2, 3, 1))
plt.tight_layout()
plt.show()



# === Define 2x3 classification ===
def assign_category(WSPD, SRAD):
    if WSPD < 2:
        if SRAD < 200:
            return "CAT1"
        elif 200 <= SRAD <= 500:
            return "CAT2"
    elif 2 <= WSPD <= 5:
        if SRAD < 200:
            return "CAT3"
        elif 200 <= SRAD <= 500:
            return "CAT4"
    elif WSPD > 5:
        if SRAD < 200:
            return "CAT5"
        elif 200 <= SRAD <= 500:
            return "CAT6"
    return "NO CAT"

# Apply category
df['Category'] = df.apply(lambda row: assign_category(row['WSPD'], row['SRAD']), axis=1)

# Define bin labels for pivoting
def ws_bin(wspd):
    if wspd < 2:
        return '<2 m/s'
    elif 2 <= wspd <= 5:
        return '2–5 m/s'
    else:
        return '>5 m/s'

def sr_bin(srad):
    if srad < 200:
        return '<200 W/m²'
    elif 200 <= srad <= 500:
        return '200–500 W/m²'
    else:
        return 'EXCLUDE'

# Assign bins
df['WSPD_bin'] = df['WSPD'].apply(ws_bin)
df['SRAD_bin'] = df['SRAD'].apply(sr_bin)

# Filter out SRAD > 500
df = df[df['SRAD_bin'] != 'EXCLUDE']

# Set category orders
ws_order = ['<2 m/s', '2–5 m/s', '>5 m/s']
sr_order = ['<200 W/m²', '200–500 W/m²']

df['WSPD_bin'] = pd.Categorical(df['WSPD_bin'], categories=ws_order, ordered=True)
df['SRAD_bin'] = pd.Categorical(df['SRAD_bin'], categories=sr_order, ordered=True)

# Pivot tables
pivot_avg = df.pivot_table(values='Tmin', index='WSPD_bin', columns='SRAD_bin', aggfunc='mean')
pivot_counts = df.pivot_table(values='Tmin', index='WSPD_bin', columns='SRAD_bin', aggfunc='count')

# Print summary
print("\n=== Average Tmin (°C) by WSPD and SRAD bins (Ordered) ===")
print(pivot_avg.round(2))

print("\n=== Sample Counts by WSPD and SRAD bins (Ordered) ===")
print(pivot_counts)

# Plot heatmap
plt.figure(figsize=(7, 5))

sns.heatmap(pivot_avg, annot=True, fmt=".2f", cmap="coolwarm_r", linewidths=0.5,
            linecolor='gray', vmin=-1.8, vmax=1.8,
            cbar_kws={'label': 'Avg (KYMN-ASOS) Tmin (°C)',
                      'ticks': np.arange(-1.8, 1.81, 0.6)})

plt.xlabel('Solar Radiation Bin', fontsize=12)
plt.ylabel('Wind Speed Bin', fontsize=12)
plt.xticks(rotation=0)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()
#=================================================================================================================================================================================
#07302025 HEAT MAP KYMN-COOP T-MIN SAME LEGEND
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\Tmin\KYMNCOOP_Tmin_SRAD_WSPD.csv')

# Ensure necessary columns are numeric
df['Tmin'] = pd.to_numeric(df['Tmin'], errors='coerce')
df['SRAD'] = pd.to_numeric(df['SRAD'], errors='coerce')
df['WSPD'] = pd.to_numeric(df['WSPD'], errors='coerce')

# Convert the 'Date' column to datetime
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
else:
    df['Date'] = pd.to_datetime(df['LocalTimestampCollected']).dt.date    
    
def assign_category(WSPD, SRAD):
    if WSPD < 2:
        if SRAD < 200:
            return "CAT1"
        elif 200 <= SRAD <= 500:
            return "CAT2"
    elif 2 <= WSPD <= 5:
        if SRAD < 200:
            return "CAT3"
        elif 200 <= SRAD <= 500:
            return "CAT4"
    elif WSPD > 5:
        if SRAD < 200:
            return "CAT5"
        elif 200 <= SRAD <= 500:
            return "CAT6"
    return "NO CAT"

# Apply bin assignment
df['Category'] = df.apply(lambda row: assign_category(row['WSPD'], row['SRAD']), axis=1)

# Define bin order and assign as ordered category
bin_order = ["CAT1", "CAT2", "CAT3", "CAT4", "CAT5", "CAT6"]
df['Category'] = pd.Categorical(df['Category'], categories=bin_order, ordered=True)

# Compute average Tmax and sample size per category
average_diff_per_bin = df.groupby('Category', observed=True)['Tmin'].mean()
bin_counts = df.groupby('Category', observed=True)['Tmin'].count()

# Plot bar chart of average Tmax per category
plt.figure(figsize=(8, 4))
ax = average_diff_per_bin.plot(kind='bar', color='blue', edgecolor='black')

# Add sample count annotations
for i, (val, count) in enumerate(zip(average_diff_per_bin, bin_counts)):
    offset = 0.2 if val >= 0 else -0.4
    va = 'bottom' if val >= 0 else 'top'
    ax.text(i, val + offset, f'{count}', ha='center', va=va, fontsize=13)

plt.ylabel('Avg (KYMN-COOP) Tmin (°C)', fontsize=12)
plt.xlabel('Category', fontsize=14)
plt.grid(True, axis='y')
plt.xticks(rotation=0, fontsize=13)
plt.yticks(fontsize=13)
plt.ylim(-2, 2)
plt.yticks(range(-2, 3, 1))
plt.tight_layout()
plt.show()



# === Define 2x3 classification ===
def assign_category(WSPD, SRAD):
    if WSPD < 2:
        if SRAD < 200:
            return "CAT1"
        elif 200 <= SRAD <= 500:
            return "CAT2"
    elif 2 <= WSPD <= 5:
        if SRAD < 200:
            return "CAT3"
        elif 200 <= SRAD <= 500:
            return "CAT4"
    elif WSPD > 5:
        if SRAD < 200:
            return "CAT5"
        elif 200 <= SRAD <= 500:
            return "CAT6"
    return "NO CAT"

# Apply category
df['Category'] = df.apply(lambda row: assign_category(row['WSPD'], row['SRAD']), axis=1)

# Define bin labels for pivoting
def ws_bin(wspd):
    if wspd < 2:
        return '<2 m/s'
    elif 2 <= wspd <= 5:
        return '2–5 m/s'
    else:
        return '>5 m/s'

def sr_bin(srad):
    if srad < 200:
        return '<200 W/m²'
    elif 200 <= srad <= 500:
        return '200–500 W/m²'
    else:
        return 'EXCLUDE'

# Assign bins
df['WSPD_bin'] = df['WSPD'].apply(ws_bin)
df['SRAD_bin'] = df['SRAD'].apply(sr_bin)

# Filter out SRAD > 500
df = df[df['SRAD_bin'] != 'EXCLUDE']

# Set category orders
ws_order = ['<2 m/s', '2–5 m/s', '>5 m/s']
sr_order = ['<200 W/m²', '200–500 W/m²']

df['WSPD_bin'] = pd.Categorical(df['WSPD_bin'], categories=ws_order, ordered=True)
df['SRAD_bin'] = pd.Categorical(df['SRAD_bin'], categories=sr_order, ordered=True)

# Pivot tables
pivot_avg = df.pivot_table(values='Tmin', index='WSPD_bin', columns='SRAD_bin', aggfunc='mean')
pivot_counts = df.pivot_table(values='Tmin', index='WSPD_bin', columns='SRAD_bin', aggfunc='count')

# Print summary
print("\n=== Average Tmin (°C) by WSPD and SRAD bins (Ordered) ===")
print(pivot_avg.round(2))

print("\n=== Sample Counts by WSPD and SRAD bins (Ordered) ===")
print(pivot_counts)

# Plot heatmap
plt.figure(figsize=(7, 5))

sns.heatmap(pivot_avg, annot=True, fmt=".2f", cmap="coolwarm_r", linewidths=0.5,
            linecolor='gray', vmin=-1.8, vmax=1.8,
            cbar_kws={'label': 'Avg (KYMN-COOP) Tmin (°C)',
                      'ticks': np.arange(-1.8, 1.81, 0.6)})

plt.xlabel('Solar Radiation Bin', fontsize=12)
plt.ylabel('Wind Speed Bin', fontsize=12)
plt.xticks(rotation=0)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()
#=================================================================================================================================================================================
#12182024 CLEANING ROWS WITH #VALUE! THESE ARE MISSING DATA
import pandas as pd

file_path = r"C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\BLRK7.csv"
df = pd.read_csv(file_path)

df_cleaned = df[~df.apply(lambda x: x.astype(str).str.contains('#VALUE!', na=False)).any(axis=1)]

# Display the cleaned dataframe
print(df_cleaned)

# Optionally, save the cleaned data to a new CSV file
output_path = r"C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\BLRK77.csv"
df_cleaned.to_csv(output_path, index=False)
#=================================================================================================================================================================================
#12182024 SEARCH FOR MISSING DAYS 
import pandas as pd

# Load data
df = pd.read_csv(r"C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\MROK7.csv")
df['Day'] = pd.to_datetime(df['Day'])  # Convert to datetime

# Generate full date range
full_range = pd.date_range(start='2011-01-01', end='2020-12-31')

# Find missing days
missing_days = full_range.difference(df['Day'])
print("Missing Days:")
print(missing_days)
#=================================================================================================================================================================================
#Code_To_Download_DEM_Tiles
import requests
import os

# Define the S3 bucket URL and the desired file pattern
bucket_url = "https://kyfromabove.s3.us-west-2.amazonaws.com/elevation/DEM/Phase1/"

station = ["N084E356", "N084E357", "N085E356", "N085E357", "N107E327", "N107E328", "N120E346", "N120E347", "N121E346", 
           "N121E347", "N077E359", "N077E360", "N078E359", "N078E360"
    
]


year_start = 2010  # Start year
year_end = 2019  # End year

# Create a folder to store downloaded files
output_folder = r"C:\DEM_Stations"
os.makedirs(output_folder, exist_ok=True)

# Loop through the specified latitude and longitude ranges
for i in station:
    # Loop through the specified year range
    for year in range(year_start, year_end):
        # Create the file name
        file_name = f"{i}_{year}_DEM_Phase1_cog.tif"
        file_url = os.path.join(bucket_url, file_name)
        print(file_name)
        # Download the file
        response = requests.get(file_url)
            
        if response.status_code == 200:
            # Save the file locally
            with open(os.path.join(output_folder, file_name), 'wb') as f:
                f.write(response.content)
            print(f"Downloaded: {file_name}")
        else:
            print(f"File not found: {file_name}")

print("Download complete.")
#=================================================================================================================================================================================
#03152025 OVERALL KYMN Tmin BY ASOS Tmin by KYMN Tmin OR KYMN Tmin by COOP Tmin
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNASOS\ALL\ALLSTN_KYMNASOS.csv')

# Define the bin assignment function
def assign_bin(TAIR):
    if TAIR <= -10:
        return "<-10"
    elif -10 < TAIR <= -7.5:
        return "-10 to -7.5"
    elif -7.5 < TAIR <= -5:
        return "-7.5 to -5"
    elif -5 < TAIR <= -2.5:
        return "-5 to -2.5"
    elif -2.5 < TAIR <= 0:
        return "-2.5 to 0"
    elif 0 < TAIR <= 2.5:
        return "0 to 2.5"  
    elif 2.5 < TAIR <= 5:
        return "2.5 to 5"
    elif 5 < TAIR <= 7.5:
        return "5 to 7.5"
    elif 7.5 < TAIR <= 10:
        return "7.5 to 10"
    elif 10 < TAIR <= 12.5:
        return "10 to 12.5"
    elif 12.5 < TAIR <= 15:
        return "12.5 to 15"
    elif 15 < TAIR <= 17.5:
        return "15 to 17.5"
    elif 17.5 < TAIR <= 20:
        return "17.5 to 20"
    elif 20 < TAIR <= 22.5:
        return "20 to 22.5"
    elif 22.5 < TAIR <= 25:
        return "22.5 to 25"
    elif 25 < TAIR <= 27.5:
        return "25 to 27.5"
    elif 27.5 < TAIR <= 30:
        return "27.5 to 30"
    elif 30 < TAIR <= 32.5:
        return "30 to 32.5"
    elif 32.5 < TAIR <= 35:
        return "32.5 to 35"
    elif 35 < TAIR <= 37.5:
        return "35 to 37.5"
    elif 37.5 < TAIR <= 40:
        return "37.5 to 40"
    elif TAIR > 40:  
        return ">40"
    
# Calculate the difference and create a new column 'KYMN_minus_COOP'
df['Tmax_minus_Tmax1'] = df['Tmax'] - df['Tmax1']

# Apply the binning function to 'KYMN' and set it as an ordered categorical type
df['Tmax_Bin'] = df['Tmax'].apply(assign_bin)

# Define the order of the bins
bin_order = ["<-10", "-10 to -7.5", "-7.5 to -5",  "-5 to -2.5", "-2.5 to 0", "0 to 2.5", "2.5 to 5",
                          "5 to 7.5", "7.5 to 10", "10 to 12.5", "12.5 to 15", "15 to 17.5", "17.5 to 20", 
                          "20 to 22.5", "22.5 to 25", "25 to 27.5", "27.5 to 30", "30 to 32.5", "32.5 to 35", 
                          "35 to 37.5", "37.5 to 40", ">40"]


#bin_order = ["<-4", "-4 to -3", "-3 to -2", "-2 to -1", "-1 to 0", "0 to 1", "1 to 2", "2 to 3", "3 to 4", ">4"]


# Convert 'KYMN_Bin' to an ordered categorical type
df['Tmax_Bin'] = pd.Categorical(df['Tmax_Bin'], categories=bin_order, ordered=True)

# Calculate the average of KYMN_minus_COOP for each bin
average_diff_per_bin = df.groupby('Tmax_Bin', observed=True)['Tmax_minus_Tmax1'].mean()

# Calculate the count of data points in each bin
bin_counts = df.groupby('Tmax_Bin', observed=True)['Tmax_minus_Tmax1'].count()

# Plotting the bar chart
plt.figure(figsize=(10, 6))
ax = average_diff_per_bin.plot(kind='bar', color='red', edgecolor='black')

# Add only the sample sizes (without 'n=') on top or below each bar
for i, count in enumerate(bin_counts):
    if i in [0, 1, 3, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 21, 15, 16, 17, 18, 20]:  # Specify indices where the sample size should go below
        ax.text(i, average_diff_per_bin[i] - 0.2, f'{count}', ha='center', va='top', fontsize=12)
    elif i in [22, 23, 24, 25, 26, 27]:  # Specify indices where the sample size should go above
        ax.text(i, average_diff_per_bin[i] + 0.2, f'{count}', ha='center', va='bottom', fontsize=12)
    else:  # Default for remaining indices (if any)
        ax.text(i, average_diff_per_bin[i] + 0.5, f'{count}', ha='center', va='bottom', fontsize=12)


# Customize the plot
plt.xlabel('KYMN (Tmax°C)', fontsize=18)
plt.ylabel('Average KYMN - ASOS (Tmax °C)', fontsize=18)
plt.tick_params(axis='both', labelsize=24)
plt.grid(True, axis='y')
plt.xticks(rotation=90, fontsize=16)
plt.ylim(-2, 2)  # Adjust based on your data range
plt.yticks(rotation=0, fontsize=16)
plt.tight_layout()

# Show the plot
plt.show()
#=================================================================================================================================================================================
#03152025 OVERALL KYMN Tmax BY ASOS Tmax by KYMN Tmax OR KYMN Tmax by COOP Tmax
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the data
df = pd.read_csv(r'C:\Users\olf42060\OneDrive - Western Kentucky University\Desktop\TEMPERATURE\KYMNCOOP\ALL\ALLSTN_KYMNCOOP.csv')

# Define the bin assignment function
def assign_bin(TAIR):
    if TAIR <= -10:
        return "<-10"
    elif -10 < TAIR <= -7.5:
        return "-10 to -7.5"
    elif -7.5 < TAIR <= -5:
        return "-7.5 to -5"
    elif -5 < TAIR <= -2.5:
        return "-5 to -2.5"
    elif -2.5 < TAIR <= 0:
        return "-2.5 to 0"
    elif 0 < TAIR <= 2.5:
        return "0 to 2.5"  
    elif 2.5 < TAIR <= 5:
        return "2.5 to 5"
    elif 5 < TAIR <= 7.5:
        return "5 to 7.5"
    elif 7.5 < TAIR <= 10:
        return "7.5 to 10"
    elif 10 < TAIR <= 12.5:
        return "10 to 12.5"
    elif 12.5 < TAIR <= 15:
        return "12.5 to 15"
    elif 15 < TAIR <= 17.5:
        return "15 to 17.5"
    elif 17.5 < TAIR <= 20:
        return "17.5 to 20"
    elif 20 < TAIR <= 22.5:
        return "20 to 22.5"
    elif 22.5 < TAIR <= 25:
        return "22.5 to 25"
    elif 25 < TAIR <= 27.5:
        return "25 to 27.5"
    elif 27.5 < TAIR <= 30:
        return "27.5 to 30"
    elif 30 < TAIR <= 32.5:
        return "30 to 32.5"
    elif 32.5 < TAIR <= 35:
        return "32.5 to 35"
    elif 35 < TAIR <= 37.5:
        return "35 to 37.5"
    elif 37.5 < TAIR <= 40:
        return "37.5 to 40"
    elif TAIR > 40:  
        return ">40"
    
# Calculate the difference and create a new column 'KYMN_minus_COOP'
df['Tmin_minus_Tmin1'] = df['Tmin'] - df['Tmin1']

# Apply the binning function to 'KYMN' and set it as an ordered categorical type
df['Tmin_Bin'] = df['Tmin'].apply(assign_bin)

# Define the order of the bins
bin_order = ["<-10", "-10 to -7.5", "-7.5 to -5",  "-5 to -2.5", "-2.5 to 0", "0 to 2.5", "2.5 to 5",
                          "5 to 7.5", "7.5 to 10", "10 to 12.5", "12.5 to 15", "15 to 17.5", "17.5 to 20", 
                          "20 to 22.5", "22.5 to 25", "25 to 27.5", "27.5 to 30", "30 to 32.5", "32.5 to 35", 
                          "35 to 37.5", "37.5 to 40", ">40"]

# Convert 'KYMN_Bin' to an ordered categorical type
df['Tmin_Bin'] = pd.Categorical(df['Tmin_Bin'], categories=bin_order, ordered=True)

# Calculate the average of KYMN_minus_COOP for each bin
average_diff_per_bin = df.groupby('Tmin_Bin', observed=True)['Tmin_minus_Tmin1'].mean()

# Calculate the count of data points in each bin
bin_counts = df.groupby('Tmin_Bin', observed=True)['Tmin_minus_Tmin1'].count()

# Plotting the bar chart
plt.figure(figsize=(10, 6))
ax = average_diff_per_bin.plot(kind='bar', color='blue', edgecolor='black')

# Add only the sample sizes (without 'n=') on top or below each bar
for i, count in enumerate(bin_counts):
    if i in [0, 1, 2, 3, 4, 5, 16, 17, 18, 20, 19, 21]:  # Specify indices where the sample size should go below
        ax.text(i, average_diff_per_bin[i] - 0.2, f'{count}', ha='center', va='top', fontsize=12)
    elif i in [5, 7, 22, 23, 24, 25, 26, 27, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]:  # Specify indices where the sample size should go above
        ax.text(i, average_diff_per_bin[i] + 0.2, f'{count}', ha='center', va='bottom', fontsize=12)
    else:  # Default for remaining indices (if any)
        ax.text(i, average_diff_per_bin[i] + 0.5, f'{count}', ha='center', va='bottom', fontsize=12)


# Customize the plot
plt.xlabel('KYMN (Tmin °C)', fontsize=18)
plt.ylabel('Average KYMN - COOP (Tmin °C)', fontsize=18)
plt.tick_params(axis='both', labelsize=24)
plt.grid(True, axis='y')
plt.xticks(rotation=90, fontsize=16)
plt.ylim(-2, 2)  # Adjust based on your data range
plt.yticks(rotation=0, fontsize=16)
plt.tight_layout()

# Show the plot
plt.show()
