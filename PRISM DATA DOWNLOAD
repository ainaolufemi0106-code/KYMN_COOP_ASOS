import os
import urllib.request
from datetime import datetime, timedelta
from tqdm import tqdm
import zipfile
import rasterio
from rasterio.mask import mask
from shapely.geometry import box
import geopandas as gpd

# -------------------------------
# Paths
# -------------------------------
folder = r"C:\Users\USER\OneDrive - Western Kentucky University\Desktop\FLOOD CONTROL"

# NEW: directory to store clipped GeoTIFFs
tif_out_dir = os.path.join(folder, "tiff_files")
os.makedirs(tif_out_dir, exist_ok=True)

base_url = "https://services.nacse.org/prism/data/get/us"
resolution = "800m"
clim_var = "ppt"

start = datetime.strptime("1981-01-01", "%Y-%m-%d")
stop  = datetime.strptime("1981-01-02", "%Y-%m-%d")

# San Diego bounding box (lat/lon)
san_diego_bbox = (-117.3, 32.5, -116.9, 33.0)

# -------------------------------
# Progress bar helper
# -------------------------------
def _progress_hook(block_num, block_size, total_size, t):
    downloaded = block_num * block_size
    if total_size > 0:
        t.update(min(block_size, total_size - t.n))
    else:
        t.update(downloaded - t.n)

# -------------------------------
# Crop function (CRS-safe)
# -------------------------------
def crop_to_bbox(input_file, output_file, bbox):
    with rasterio.open(input_file) as src:

        gdf = gpd.GeoDataFrame(
            geometry=[box(*bbox)],
            crs="EPSG:4326"
        ).to_crs(src.crs)

        out_image, out_transform = mask(src, gdf.geometry, crop=True)

        out_meta = src.meta.copy()
        out_meta.update({
            "driver": "GTiff",
            "height": out_image.shape[1],
            "width": out_image.shape[2],
            "transform": out_transform
        })

        with rasterio.open(output_file, "w", **out_meta) as dest:
            dest.write(out_image)

# -------------------------------
# Main loop
# -------------------------------
while start <= stop:
    day = start.strftime("%Y%m%d")
    url = f"{base_url}/{resolution}/{clim_var}/{day}"
    zip_file = os.path.join(folder, f"PRISM_{clim_var}_{day}.zip")

    try:
        # Download
        with tqdm(desc=f"Downloading {day}", unit="B", unit_scale=True, unit_divisor=1024) as t:
            urllib.request.urlretrieve(
                url,
                zip_file,
                reporthook=lambda b, bs, ts: _progress_hook(b, bs, ts, t)
            )

        # Extract
        with zipfile.ZipFile(zip_file, "r") as zip_ref:
            extract_folder = os.path.join(folder, f"PRISM_{clim_var}_{day}")
            zip_ref.extractall(extract_folder)

            all_files = os.listdir(extract_folder)
            raster_files = [f for f in all_files if f.endswith((".tif", ".bil", ".asc"))]

            if not raster_files:
                print(f"✗ No raster found for {day}")
                start += timedelta(days=1)
                continue

            raster_path = os.path.join(extract_folder, raster_files[0])

            # NEW: save clipped file to tiff_files directory
            clipped_file = os.path.join(
                tif_out_dir,
                f"SanDiego_{clim_var}_{day}.tif"
            )

            crop_to_bbox(raster_path, clipped_file, san_diego_bbox)

            print(f"✓ Saved clipped San Diego GeoTIFF: {clipped_file}")

    except Exception as e:
        print(f"✗ Error processing {day}: {e}")

    start += timedelta(days=1)

print("All PRISM San Diego GeoTIFFs saved to tiff_files/")


Prism GeoTiff files to CSV
=================================================================================
import rasterio
import numpy as np
import pandas as pd

tif = r"C:\Users\USER\OneDrive - Western Kentucky University\Desktop\FLOOD CONTROL\tiff_files\SanDiego_ppt_19880919.tif"

with rasterio.open(tif) as src:
    data = src.read(1)
    transform = src.transform
    nodata = src.nodata

data = np.where(data == nodata, np.nan, data)
data[data < 0] = np.nan

rows, cols = data.shape

records = []

for r in range(rows):
    for c in range(cols):
        val = data[r, c]
        if not np.isnan(val):
            lon, lat = transform * (c, r)
            records.append([lat, lon, val])

df = pd.DataFrame(records, columns=["lat", "lon", "precip_mm"])
df.to_csv(r"C:\Users\USER\OneDrive - Western Kentucky University\Desktop\SD_19880919.csv", index=False)
print(df)


Extract the daily data GeoTiff to a sinfle CSV file
=====================================================================================
import glob
import rasterio
import numpy as np
import pandas as pd
import os
from datetime import datetime

# Folder with clipped San Diego GeoTIFFs
tif_folder = r"C:\Users\USER\OneDrive - Western Kentucky University\Desktop\FLOOD CONTROL\tiff_files"
tif_files = sorted(glob.glob(os.path.join(tif_folder, "SanDiego_ppt_*.tif")))

print(f"Found {len(tif_files)} files to process")

all_data = []

for tif in tif_files:
    try:
        with rasterio.open(tif) as src:
            data = src.read(1)
            nodata = src.nodata
            transform = src.transform
            
            # Get row and column indices
            rows, cols = np.where(np.ones_like(data))
            
            # Get coordinates for each pixel
            xs, ys = rasterio.transform.xy(transform, rows, cols)
            
            # Get precipitation values
            precip_values = data[rows, cols]
            
        # Extract date from filename
        date_str = os.path.basename(tif).split("_")[-1].replace(".tif", "")
        
        # Convert YYYYMMDD to YYYY-MM-DD
        try:
            date_obj = datetime.strptime(date_str, "%Y%m%d")
            formatted_date = date_obj.strftime("%Y-%m-%d")
        except:
            formatted_date = date_str
        
        # Create DataFrame for this date
        df_day = pd.DataFrame({
            'date': formatted_date,
            'longitude': xs,
            'latitude': ys,
            'row': rows,
            'col': cols,
            'precip_mm': precip_values
        })
        
        # Filter out NoData values
        if nodata is not None:
            df_day = df_day[df_day['precip_mm'] != nodata]
        
        # Filter out negative values
        df_day = df_day[df_day['precip_mm'] >= 0]
        
        all_data.append(df_day)
        print(f" Processed {formatted_date}: {len(df_day)} valid pixels")
        
    except Exception as e:
        print(f"✗ Error processing {os.path.basename(tif)}: {e}")
===========================================================================================================
# Combine all data into one DataFrame
if all_data:
    df_combined = pd.concat(all_data, ignore_index=True)
    
    # Save to CSV
    csv_out = os.path.join(tif_folder, "SanDiego_PRISM_all_pixels.csv")
    df_combined.to_csv(csv_out, index=False)
    
    print(f"\n CSV saved to {csv_out}")
    print(f" Total records: {len(df_combined):,}")
    print(f" Date range: {df_combined['date'].min()} to {df_combined['date'].max()}")
    print(f" Unique dates: {df_combined['date'].nunique()}")
    print(f"\nData preview:")
    print(df_combined.head(10))
else:
    print("✗ No valid data extracted")
===========================================================================================================
if all_data:
    df_combined = pd.concat(all_data, ignore_index=True)
    
    # Ensure date column is datetime (in case it wasn't)
    df_combined['date'] = pd.to_datetime(df_combined['date'], errors='coerce')
    
    # Remove any rows where date conversion failed
    df_combined = df_combined.dropna(subset=['date'])
    
    # Create year-month column
    df_combined['year_month'] = df_combined['date'].dt.to_period('M')
    
    # Group by longitude, latitude, and year-month, then sum precipitation
    df_monthly = df_combined.groupby(['longitude', 'latitude', 'row', 'col', 'year_month'], as_index=False).agg({
        'precip_mm': 'sum'
    })
    
    # Rename column to indicate monthly sum
    df_monthly.rename(columns={'precip_mm': 'monthly_precip_mm'}, inplace=True)
    
    # Convert year_month back to string for CSV export
    df_monthly['year_month'] = df_monthly['year_month'].astype(str)
    
    # Save monthly data to CSV
    csv_monthly = os.path.join(tif_folder, "SanDiego_PRISM_monthly_sums.csv")
    df_monthly.to_csv(csv_monthly, index=False)
    
    print(f"\n Monthly CSV saved to {csv_monthly}")
    print(f" Total monthly records: {len(df_monthly):,}")
    print(f" Unique months: {df_monthly['year_month'].nunique()}")
    print(f" Unique grid cells: {df_monthly[['longitude', 'latitude']].drop_duplicates().shape[0]}")
    print(f"\nMonthly data preview:")
    print(df_monthly.head(10))
    
    # Optional: Also save the daily data
    csv_daily = os.path.join(tif_folder, "SanDiego_PRISM_daily.csv")
    df_combined.drop('year_month', axis=1).to_csv(csv_daily, index=False)
    print(f"\n Daily CSV also saved to {csv_daily}")
    
else:
    print("✗ No valid data extracted")
===========================================================================================================
import pandas as pd
import os

# Read the seasonal data
tif_folder = r"C:\Users\USER\OneDrive - Western Kentucky University\Desktop\FLOOD CONTROL\tiff_files"
csv_seasonal = os.path.join(tif_folder, "SanDiego_PRISM_seasonal_sums.csv")

df_seasonal = pd.read_csv(csv_seasonal)

# Extract season name and year from the season column
df_seasonal['season_name'] = df_seasonal['season'].str.split('-').str[1]
df_seasonal['season_year'] = df_seasonal['season'].str.split('-').str[0].astype(int)

# Filter for years 1981-2020
df_filtered = df_seasonal[(df_seasonal['season_year'] >= 1981) & (df_seasonal['season_year'] <= 2020)]

# Group by longitude, latitude, and season name (across all years)
df_all_seasons = df_filtered.groupby(['longitude', 'latitude', 'season_name'], as_index=False).agg({
    'seasonal_precip_mm': 'sum'
})

# Rename column to indicate total across all years
df_all_seasons.rename(columns={'seasonal_precip_mm': 'total_precip_mm_1981_2020'}, inplace=True)

# Save combined seasonal data
csv_all_seasons = os.path.join(tif_folder, "SanDiego_PRISM_all_seasons_1981_2020.csv")
df_all_seasons.to_csv(csv_all_seasons, index=False)

print(f" All seasons (1981-2020) CSV saved to {csv_all_seasons}")
print(f" Total records: {len(df_all_seasons):,}")
print(f" Unique grid cells: {df_all_seasons[['longitude', 'latitude']].drop_duplicates().shape[0]}")
print(f"\nData preview:")
print(df_all_seasons.head(10))

# Create separate files for each season
for season in ['Winter', 'Spring', 'Summer', 'Fall']:
    df_season = df_all_seasons[df_all_seasons['season_name'] == season].copy()
    df_season = df_season[['longitude', 'latitude', 'total_precip_mm_1981_2020']]
    
    csv_season = os.path.join(tif_folder, f"SanDiego_PRISM_{season}_1981_2020.csv")
    df_season.to_csv(csv_season, index=False)
    
    print(f"n {season} (1981-2020) CSV saved to {csv_season}")
    print(f"  Records: {len(df_season):,}")
    print(f"  Preview:")
    print(df_season.head(5))
======================================================================================================yearly totals

import pandas as pd
import os

# Read the monthly data
tif_folder = r"C:\Users\USER\OneDrive - Western Kentucky University\Desktop\FLOOD CONTROL\tiff_files"
csv_monthly = os.path.join(tif_folder, "SanDiego_PRISM_monthly_sums.csv")

df_monthly = pd.read_csv(csv_monthly)

# Extract year from year_month column (format: "YYYY-MM")
df_monthly['year'] = df_monthly['year_month'].str.split('-').str[0].astype(int)

# Group by longitude, latitude, and year, then sum precipitation
df_yearly = df_monthly.groupby(['longitude', 'latitude', 'year'], as_index=False).agg({
    'monthly_precip_mm': 'sum'
})

# Rename column to indicate yearly sum
df_yearly.rename(columns={'monthly_precip_mm': 'yearly_precip_mm'}, inplace=True)

# Save yearly data to CSV
csv_yearly = os.path.join(tif_folder, "SanDiego_PRISM_yearly_sums.csv")
df_yearly.to_csv(csv_yearly, index=False)

print(f" Yearly CSV saved to {csv_yearly}")
print(f" Total yearly records: {len(df_yearly):,}")
print(f" Unique years: {df_yearly['year'].nunique()}")
print(f" Year range: {df_yearly['year'].min()} - {df_yearly['year'].max()}")
print(f" Unique grid cells: {df_yearly[['longitude', 'latitude']].drop_duplicates().shape[0]}")
print(f"\nYearly data preview:")
print(df_yearly.head(10))

# Optional: Filter for specific year range (e.g., 1981-2020)
df_yearly_filtered = df_yearly[(df_yearly['year'] >= 1981) & (df_yearly['year'] <= 2020)]

csv_yearly_filtered = os.path.join(tif_folder, "SanDiego_PRISM_yearly_sums_1981_2020.csv")
df_yearly_filtered.to_csv(csv_yearly_filtered, index=False)

print(f"\n Filtered yearly (1981-2020) CSV saved to {csv_yearly_filtered}")
print(f" Total records: {len(df_yearly_filtered):,}")
